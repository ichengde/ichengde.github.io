<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>chegde 杂货店</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://chegde.github.io/"/>
  <updated>2018-01-05T14:27:02.000Z</updated>
  <id>http://chegde.github.io/</id>
  
  <author>
    <name>chegde</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Active learning of neuron morphology for accurate automated tracing of neurites</title>
    <link href="http://chegde.github.io/2016/07/15/Active-learning-of-neuron-morphology-for-accurate-automated-tracing-of-neurites/"/>
    <id>http://chegde.github.io/2016/07/15/Active-learning-of-neuron-morphology-for-accurate-automated-tracing-of-neurites/</id>
    <published>2016-07-14T23:32:42.000Z</published>
    <updated>2018-01-05T14:27:02.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Active-learning-of-neuron-morphology-for-accurate-automated-tracing-of-neurites"><a href="#Active-learning-of-neuron-morphology-for-accurate-automated-tracing-of-neurites" class="headerlink" title="Active learning of neuron morphology for accurate automated tracing of neurites"></a>Active learning of neuron morphology for accurate automated tracing of neurites</h1><h1 id="神经元形态主动学习-对-神经轴突的精确自动追踪"><a href="#神经元形态主动学习-对-神经轴突的精确自动追踪" class="headerlink" title="神经元形态主动学习 对 神经轴突的精确自动追踪"></a>神经元形态主动学习 对 神经轴突的精确自动追踪</h1><h5 id="阅读本文需要proxy-依赖imgur图床"><a href="#阅读本文需要proxy-依赖imgur图床" class="headerlink" title="阅读本文需要proxy,依赖imgur图床"></a>阅读本文需要proxy,依赖imgur图床</h5><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献:"></a>参考文献:</h2><p><a href="http://journal.frontiersin.org/article/10.3389/fnana.2014.00037/full" target="_blank" rel="noopener">http://journal.frontiersin.org/article/10.3389/fnana.2014.00037/full</a></p><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>Automating the process of neurite tracing from light microscopy stacks of images is essential for large-scale or high-throughput quantitative studies of neural circuits. While the general layout of labeled neurites can be captured by many automated tracing algorithms, it is often not possible to differentiate reliably between the processes belonging to different cells. The reason is that some neurites in the stack may appear broken due to imperfect labeling, while others may appear fused due to the limited resolution of optical microscopy. Trained neuroanatomists routinely resolve such topological ambiguities during manual tracing tasks by combining information about distances between branches, branch orientations, intensities, calibers, tortuosities, colors, as well as the presence of spines or boutons. Likewise, to evaluate different topological scenarios automatically, we developed a machine learning approach that combines many of the above mentioned features. A specifically designed confidence measure was used to actively train the algorithm during user-assisted tracing procedure. Active learning significantly reduces the training time and makes it possible to obtain less than 1% generalization error rates by providing few training examples. To evaluate the overall performance of the algorithm a number of image stacks were reconstructed automatically, as well as manually by several trained users, making it possible to compare the automated traces to the baseline inter-user variability. Several geometrical and topological features of the traces were selected for the comparisons. These features include the total trace length, the total numbers of branch and terminal points, the affinity of corresponding traces, and the distances between corresponding branch and terminal points. Our results show that when the density of labeled neurites is sufficiently low, automated traces are not significantly different from manual reconstructions obtained by trained users.</p><p>对于神经回路(neural circuits)高通量研究,从光学研究大量图像的神经追踪自动化是必不可少的.<br>当被标记的神经的通常分布可以被许多自动追踪算法捕获,但事实上分辨神经元分属于不同细胞常常是不可能的.<br>原因是一些在一堆的神经元常常出现断裂,由于不完美的”神经元的扫描”,其他的还会出现融合,由于光学显微有限的方法.<br>专业的神经解剖学一般依靠组合信息例如分支节点的距离,分支方向强度,口径,变形,颜色,刺或者棒头的存在.<br>还有,为了评估不同技术自动化脚本,我们通过上述提到的特点发展出了机器学习.<br>在用户辅助训练过程中,一种特别设计可信赖的测量适用于主动训练算法.<br>主动学习显著减少了训练时间,通过提供的少量训练样本,尽可能获取少于1%的一般错误比例.<br>为了评估算法的总体性能,大量的图像堆被自动重建以及以几个熟练用户手工重建,尽可能完成自动追踪对于基线用户间变异性.<br>在对比中选择几种追踪方法的几何和技术特征.<br>这些特征包括了总追踪长度,分支与终点之间的总数和距离,相应追踪的近似程度.<br>我们的结果表明,当标记神经的密度是足够低的,自动追踪与受过训练的用户来人工重建不会有显著不同.</p><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>Our understanding of brain functions is hindered by the lack of detailed knowledge of synaptic connectivity in the underlying neural network. With current technology it is possible to sparsely label specific populations of neurons in vivo and image their processes with high-throughput optical microscopy (see e.g., Stettler et al., 2002; Trachtenberg et al., 2002; De Paola et al., 2006; Wickersham et al., 2007; Lichtman et al., 2008; Wilt et al., 2009; Ragan et al., 2012). Imaging can be done in vivo for circuit development or plasticity studies (Trachtenberg et al., 2002), or ex vivo for circuit mapping projects (Lu et al., 2009). In the latter case, an unprecedented resolution can be achieved by first clarifying the tissue (Hama et al., 2011; Chung et al., 2013), and then imaging the entire brain from thousands of optical sections (Ragan et al., 2012). The overwhelming obstacle remaining on the way to brain mapping is accurate, high-throughput tracing of neurons (Sporns et al., 2005; Lichtman et al., 2008; Miller, 2010; Gillette et al., 2011b; Kozloski, 2011; Lichtman and Denk, 2011; Liu, 2011; Svoboda, 2011; Helmstaedter and Mitra, 2012; Van Essen and Ugurbil, 2012; Perkel, 2013). Presently, accurate traces of complex neuron morphologies can only be obtained manually, which is extremely time consuming (Stepanyants et al., 2004, 2008; Shepherd et al., 2005), and thus impractical for large reconstruction projects.</p><p>在底层神经网络中对于突触连通的细节知识的缺失阻碍了我们对脑功能的理解.<br>用现代技术是可能去少量标记特定的神经群,在vivo和通过高通量光学显微镜得到的图像.<br>成像可以在vivo完成,为了神经线路的发展或者粘性研究,或者前vivo对于神经线路测绘工程.在后来发展中,一种崭新的解决方案可以实现对组织的第一清晰度和形成整个大脑的图像变成数以前千计的光学切片.巨大的阻碍留在了如何完成大脑映射:精确高通量的神经元追踪.<br>目前,复杂神经元形态的精确追踪只能手工获得,这是极端耗时的,因此,对于大型重建工程是不切实际的.</p><p>Many automated tracing algorithms have been developed in recent years [see e.g., Al-Kofahi et al., 2002; Schmitt et al., 2004; Zhang et al., 2007; Al-Kofahi et al., 2008; Losavio et al., 2008; Peng et al., 2010; Srinivasan et al., 2010; Bas and Erdogmus, 2011; Peng et al., 2011; Turetken et al., 2011; Wang et al., 2011; Xie et al., 2011; Bas et al., 2012; Choromanska et al., 2012; Turetken et al., 2012 and Meijering, 2010; Donohue and Ascoli, 2011; Parekh and Ascoli, 2013 for review]. In general, existing algorithms can accurately capture the geometrical layout of neurites but are not guaranteed to recover their correct branching topology (Figure 1). Topological errors are inevitably present in traces obtained from low signal-to-noise images, images of non-uniformly labeled neurites, or images with high density of labeled structures. Close examination of such traces often reveals topological errors such as broken branches, missing branches, and incorrectly resolved branch crossover regions (stolen branches). This is a particular concern for high-throughput projects where topological errors can accumulate over multiple stacks. For example, while tracing a long-range axon from one optical section to the next, even a very low error-rate, say 5% per section, will almost certainly lead to erroneous connectivity after about 20 sections (typically about 10 mm), rendering the trace unusable for brain mapping projects. Clearly, the rate of topological errors in automated reconstruction projects must be carefully controlled (Chothani et al., 2011).</p><p>在近年来许多自动追踪算法已经发展,在一般情况下,现存的算法可以精确捕获到神经元的几何布局,但是不保证恢复正确分支节点的技术.<br>从低信噪比图像和非均匀地标记的神经突的图像中,对于现存的追踪获取,技术错误是不可避免的.<br>这样的追踪方法在仔细检查下,常常会发现技术错误,例如破碎的分支,缺失的分支,和错误解决的分支交叉区域.这是备受关注的高通量项目,拓扑学错误可以累积多个堆栈中,例如,当追踪长轴突从一个光学切片到下一个,即使是一个非常低的错误率,如每切片5%,几乎毫无疑问地导致错误的连通性,在大约20个切片后(通常是十毫米),致使这个追踪是不能用的对于大脑映射工程.明显的,技术错误的几率在自动化重建工程必须是小心地被控制的.</p><p>In this study we describe an active machine learning approach (Settles, 2012) that has the potential to significantly reduce the number of topological errors in automated traces. Our algorithm first detects a geometrically accurate trace with the Fast Marching method (Cohen et al., 1994; Cohen and Kimmel, 1997; Sethian, 1999; Mukherjee and Stepanyants, 2012), which was extended to incorporate multiple seed points. Next, the initial trace is dismantled to the level of individual branches, and active learning is applied to reconnect this trace based on knowledge of neuron morphology. We show that active learning does not require large sets of training examples, and the results generalize well on image stacks acquired under similar experimental conditions. What is more, when the density of labeled neurites is sufficiently low, automated traces are not significantly different from reconstructions produced manually by trained users.</p><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p>Results of this study are based on the analyses of two datasets featured at the DIADEM challenge (Brown et al., 2011). The OP dataset includes 9 image stacks containing axons of single olfactory projection neurons from Drosophila (Jefferis et al., 2007), and the L6 dataset consists of 6 image stacks containing axons of multiple layer 6 neurons imaged in layer 1 of mouse visual cortex (De Paola et al., 2006). The NCTracer software (www.neurogeometry.net) was used to trace each image stack automatically, as well as manually. The manual traces were generated independently for each stack by three trained users.</p><p>这项研究的结果是基于两个有特点的数据集在”王冠”的挑战.这OP数据集包括了9个图像堆,包含了果蝇属的单嗅觉工程神经集的轴突,和由6图像堆组成的L6数据集,包含了多层次的6个神经在小鼠视觉皮层的1层成像的轴突.NCTracer软件(www.neurogeometry.net)是被用于自动化追踪每一个图像堆,同时也可以手工.对于每一个图像堆,通过三个训练有素的用户,这手工追踪可以被独立生成.</p><h3 id="神经元的初始化追踪"><a href="#神经元的初始化追踪" class="headerlink" title="神经元的初始化追踪"></a>神经元的初始化追踪</h3><p>The Initial Trace of Neurites<br>We refer to any trace providing geometrically accurate information about the layout of neurites within an image stack as an initial trace. Numerous segmentation and tracking-based methods (see e.g., Al-Kofahi et al., 2002; Schmitt et al., 2004; Zhang et al., 2007; Al-Kofahi et al., 2008; Losavio et al., 2008; Peng et al., 2010; Srinivasan et al., 2010; Bas and Erdogmus, 2011; Peng et al., 2011; Turetken et al., 2011; Wang et al., 2011; Xie et al., 2011; Bas et al., 2012; Choromanska et al., 2012; Turetken et al., 2012) can be used to produce initial traces. In this study we adapt the Fast Marching method (Cohen et al., 1994; Cohen and Kimmel, 1997; Sethian, 1999; Mukherjee and Stepanyants, 2012) to grow the initial trace from multiple seed points (Figure 2), analogous to the way light from multiple point sources spreads through a non-uniform medium. This process is described by the Eikonal boundary value problem (Sethian, 1999):</p><p>我们查阅了任何一种追踪都带着在几何学上精确的信息,如神经元的布局,使用一个图像堆作为初始追踪.<br>许多分隔和基于追踪的方法可以用来产生初始追踪,在这项研究中,我们选用了快速行进的方法 (Cohen et al., 1994; Cohen and Kimmel, 1997; Sethian, 1999; Mukherjee and Stepanyants, 2012)从多个种子点去扩张初始追踪,类似于光线从多个点源通过非均匀媒介中传播.这个进程被描述为 光程函数边值问题(Sethian, 1999).</p><p><img src="http://i.imgur.com/UoHM0ui.png" alt=""></p><p>In this expression, vector r represents a position in the image stack (or non-uniform medium), I is the image intensity normalized to the 0–1 range (analog of the speed of light in the medium), and ∇ denotes the gradient operator. Light rays originate from the boundary, ∂S, at time zero, and the time map, T(r), provides information about the shortest time of arrival of these rays to various locations in the image. Because higher image intensities correspond to faster speeds of light propagation, the arrival time front in the image will preferentially spread along the high intensity structures of neurites (see Figure 2C).</p><p>在这个表达式中,矢量r代表在图像堆中或是在非均匀媒介中的位置,I是图像亮度 归于0-1范围内(类似于光在介质中的速度),∇代表梯度操作子.<br>光射线起源于边界,∂S在零时间，和时间对应,T(r)提供了在极短时间内这些光线到达图像中的不同位置的信息.因为更高的图像亮度代表着光传播的更快的速度.在到达时间前,图像将会优先传播沿着高亮度结构的轴突.</p><p>The Fast Marching algorithm of Sethian (Sethian, 1999) is an efficient numerical scheme for solving the Eikonal boundary value problem, Equation (1). Since the speed function in our problem is defined by the image intensity, it is always positive. For positive speed functions it is known that the Eikonal boundary value problem can be solved more efficiently than the commonly used alternative—the Hamilton-Jacobi problem of the Level Set method (Sethian, 1999). One reason is that the stability condition required for a numerical solution of the time-dependent Level Set equation is more stringent than that used to solve the Eikonal problem. Specifically, this condition requires very small time steps and thus the Level Set method is expected to be more time consuming. The second advantage of Fast Marching has to do with the outward only propagation of the fronts, which can be used to find new front points very efficiently (Sethian, 1999).</p><p>Sethian 的快速行进算法是一个高效数值方案对于求光程函数边界数值问题(方程1),在我们的问题中,速度被定义成图像的亮度,它始终为正,对于正速度函数,众所周知，在光程函数边值问题上,可以比常用的替代方法[the Hamilton-Jacobi problem of the Level Set method (Sethian, 1999)]更有效地解决。原因之一是，对于随时间变化的水平集方程的数值解所需的稳定性条件是更苛刻的,比用于解决光程函数边界数值问题。特别得，这种情况需要非常小的时间间隔，因而水平集方法预计将耗费更多的时间。快速行进的第二个优点是只在前沿,向外传播，它可用于非常有效地找到新的前进点 (Sethian, 1999).</p><p>We implement the Fast Marching algorithm (Sethian, 1999) on a discrete lattice defined by the centers of image voxels, l = (i, j, k)T. Here the time map is evolved from the boundary at T = 0 by taking the upwind solution of a discretized version of Equation (1):</p><p>我们实现快速行进算法在离散点阵形式通过图像像素的中心定义, l = (i, j, k)T.这里的时间映射是从在T = 0的边界演变,采用方程的离散版本的upwind解决方案.</p><p><img src="http://i.imgur.com/bwuC0nU.png" alt=""></p><p>Parameters (sx, sy, sz) in this expression denote the voxel dimensions which may not be the same due to a typically lower z-resolution in confocal and two-photon microscopy images.</p><p>参数(i,j,k)在这个表达式代表三维尺寸,并不相同由于一般低z分辨率在共焦和双光子显微镜图像.</p><p>The arrival time front is initialized with T = 0 at multiple seed points, which are automatically generated along the structure of neurites based on image intensity (Figure 2A). As was previously described (Mukherjee and Stepanyants, 2012), the arrival time front is allowed to travel a specified distance, Dmax, to establish a local time map. The value of Dmax has to be chosen based on two considerations: Dmax has to be larger than the caliber of neurites (3–5sx for OP and L6) not to produce short spurious branches and, at the same time, not much larger than the shortest branch that needs to be resolved by the algorithm (10sx in this study). Dmax = 15sx was used throughout this study. The path connecting the farthest point of the front to the T = 0 boundary is then found by performing gradient descent on T(i, j, k) (see Figures 2C–E). Next, the gradient descent path is added to the boundary ∂S and the Fast Marching algorithm is re-initialized from the new boundary. This process continues until a stopping condition is reached, at which point the final ∂S defines the initial trace. The stopping condition used in this study is based on the average intensity of the last added branch. When this intensity falls below a set threshold (typically 20% of the average intensity of the existing trace), Fast Marching is paused and can then be continued or terminated by the user.</p><p>在达到时间前是用T = 0在多个种子点进行初始化,是用于自动生成沿着神经元结构基于图像亮度.如先前所描述(Mukherjee and Stepanyants, 2012),在到达时间前,是被允许行进规定距离,Dmax 是建立了当地时间映射,Dmax的值基于两个方面考虑:Dmax必须比轴突的口径更大,(3–5sx for OP and L6)不产生短伪分支,与此同时,不比需要由算法来解决的最短分支大得多（10SX在这项研究中）.在整个本研究中使用DMAX = 15sx。该路径连接最接近到T = 0的边界前的最远点的路径,然后由于T（I，J，K）（参见图2C-E）进行梯度下降找到.<br>接下来,梯度下降通道被添加到边界∂S,快速行进算法从新的边界被重新初始化.<br>此过程继续进行,直到达到终止条件.在该点,最终∂S表示初始轨迹.在此研究中使用的停止条件是基于最后添加分支的平均强度.当该亮度降到低于设定的阈值(通常是已经存在的追踪的平均亮度的20%),快速行进被暂停,然后可以由用户继续或终止.</p><p><img src="http://www.frontiersin.org/files/Articles/81880/fnana-08-00037-HTML/image_m/fnana-08-00037-g002.jpg" alt=""></p><p>As long as the seed points used to initialize Fast Marching are located in the foreground and are connected by higher than background intensity paths, their Fast Marching fronts are guaranteed to collide. The gradient descent algorithm is invoked in this case as well. Here, gradient descent paths originating from the collision voxel back-propagate into every colliding region, thus connecting their T = 0 boundaries. If there is a break in intensity along a neurite linking two seed points, the Fast Marching algorithm may terminate before the fronts have a chance to collide. In addition, high levels of background intensity may lead to erroneous front collisions. These and other topological errors in the initial trace will be corrected as described in the following sections.</p><p>只要位于前景种子点通常用快速行进的初始化  而且是 通过比背景亮度更强的路径来连接, 快速行进的前端一定会碰撞. 在这个场景下,梯度下降算法效果很好,梯度下降路径起点从碰撞的三维像素反向传播到每一个碰撞的区域,因此连接到T=0的边界中.如果在亮度上有断开在神经元的两个种子点之间,快速行进算法也许会停滞在可能碰撞的前端.此外,高亮度的背景会导致接触前端的错误.在接下来所描述的部分,这和其他算法的错误在初始化追踪中将被纠正,</p><h2 id="Optimization-of-the-Initial-Trace"><a href="#Optimization-of-the-Initial-Trace" class="headerlink" title="Optimization of the Initial Trace"></a>Optimization of the Initial Trace</h2><h2 id="优化初始追踪"><a href="#优化初始追踪" class="headerlink" title="优化初始追踪"></a>优化初始追踪</h2><p>We represent the initial trace as a graph structure consisting of nodes linked by straight line segments. Each node, k, is described by its position in the stack, rk = (xk, yk, zk)T, and the caliber, Rk, of the neurite at that location. Information about connectivity among the nodes is stored in the adjacency matrix, A. We find this representation to be more convenient than the traditional SWC format of neuron morphology (Cannon et al., 1998) because the latter cannot be used to describe structures containing loops.</p><p>由直线所连接的节点组成的图形结构作为初始轨迹.每一个节点,k都用来描述它在图像栈的位置, rk = (xk, yk, zk)T,神经突起的口径:Rk,储存在邻接矩阵的节点间的连通性信息,我们发现，这表示要比传统的神经元形态SWC格式更实用 (Cannon et al., 1998)因为SWC无法描述包含回环的结构。</p><p><img src="http://www.frontiersin.org/files/Articles/81880/fnana-08-00037-HTML/image_n/fnana-08-00037-i002.gif" alt=""></p><p>Because the initial trace lies sufficiently close to the centerline of neurites, this trace can be optimized by monitoring its fitness in response to small changes in the position and caliber of every node. The fitness function used in this study, yes, consists of the intensity integrated along the trace and regularizing constraints on the positions and calibers of the connected nodes:</p><p>因为初始追踪位置十分接近神经的中间线,追踪可以通过监测它适应的每一个节点的位置和口径的微小变化去优化.在这项研究中,使用的适应调整功能，是由轨迹的整体亮度和连接节点的口径与位置的规则约束所组成的</p><p>Vectors rk in this expression specify the positions of the trace vertices, while vectors lm denote the positions of voxel centers in the image stack. Index k’ enumerates the neighbors of vertex k. Parameter λ denotes the average density of nodes in the trace, i.e. the number of nodes per voxel. Lagrange multipliers αr &gt; 0 and αR &gt; 0 control the stiffness of the regularizing constraints. The first term in this expression is the convolution of the image with the Laplacian of Gaussian. This convolution can be performed by using the Fast Fourier Transform (Press, 2007) or, in case of relatively small density of trace nodes, it may be faster to perform explicit summation over the index m. In this case, due to the fast decay of the Gaussian factor, the summation can be restricted to a small number of voxels in the vicinity of the trace (see Chothani et al., 2011 for details).</p><p>在这个表达式中,向量Rk指的是追踪顶点的位置,而向量lm表示在图像堆栈三维像素中心的位置,参数λ表示节点在跟踪的平均密度,即每像素节点的数目.拉格朗日乘子αR&gt; 0,αR&gt; 0控制的正则化约束刚度.在该表达式中的第一项是与高斯的拉普拉斯图像的卷积。这个卷积可以通过使用快速傅里叶变换（Press，2007年），或在跟踪节点的相对较小密度的情况下进行，它可以是更快地通过索引号m执行显式求和。在这种情况下，由于高斯因子的快速衰减，求和可以限制到一个小数目在跟踪的附近的体素（see Chothani et al., 2011 for details）。</p><p>Maximization of the fitness function, yes, is performed with Newton’s method (Press, 2007):</p><p>最优适应函数是牛顿法</p><p><img src="http://www.frontiersin.org/files/Articles/81880/fnana-08-00037-HTML/image_n/fnana-08-00037-i003.gif" alt=""></p><p>Variable n in this expression enumerates the iteration steps of the algorithm, parameter β &gt; 0 controls the step size, Ĥ denotes the Hessian operator acting on all the node variables {rk(n), Rk(n)}, and -1 in the exponent denotes matrix inversion. The positions and calibers of all nodes of the trace, including branch and terminal points, are synchronously updated at every iteration step. The values of all three terms in the fitness function are monitored during optimization. Optimization is terminated once the relative changes in all three quantities fall below 10−8. For the OP and L6 datasets considered in this study, the optimization procedure typically converges to the optimum solution in less than 50 steps. Optimization improves the layout of branches as well as the placement of branch and terminal points in the initial trace (Vasilkoski and Stepanyants, 2009; Chothani et al., 2011). The values of parameters αr, αR, and β are constrained by the considerations of algorithm stability, speed of convergence, and accurate representation of neurites’ curvature and caliber. Some of these issues were discussed in Vasilkoski and Stepanyants (2009) and Chothani et al. (2011).</p><p>在此表达式变量n列举算法的迭代步骤中，参数β&gt; 0的控制步长，h表示作用于所有节点的变量{RK（n）时，RK（n）}存储在黑森操作者，和-1中的指数表示矩阵求逆。的位置和跟踪，包括分支和终点的所有节点的口径，同步地在每个迭代步骤更新。在健身功能的所有三个术语的值优化过程中进行监控。一旦在所有三个量的相对变化低于10-8优化终止。对于本研究中考虑的OP和L6数据集，所述优化过程通常收敛于小于50步的最佳解决方案。优化提高分支的布局，以及在初始跟踪转移和终点的位置（Vasilkoski和Stepanyants，2009; Chothani等人，2011）。参数值αR，αR，β是由算法稳定性，收敛的速度，和突起’曲率和口径的精确表示的考虑因素的限制。其中的一些问题进行了Vasilkoski和Stepanyants（2009年）和Chothani等人讨论。 （2011年）。</p><h2 id="Learning-Branching-Morphology-of-Neurites"><a href="#Learning-Branching-Morphology-of-Neurites" class="headerlink" title="Learning Branching Morphology of Neurites"></a>Learning Branching Morphology of Neurites</h2><h2 id="学习轴突分支形态"><a href="#学习轴突分支形态" class="headerlink" title="学习轴突分支形态"></a>学习轴突分支形态</h2><p>As shown in Figure 1, even when the initial trace accurately describes the geometry of neurites, it often fails to capture the correct branching topology. To address this problem, we disconnect branches of the initial trace from one another and then assemble them into tree-like structures based on prior knowledge of neuron morphology. In order to discriminate between correct and erroneous ways to assemble branches, different branch merging scenarios are evaluated in a machine learning approach by combining information about various features of the trace. Such features may include distances between branches, branch orientations, average intensities, intensity variations, branch thicknesses, curvatures, tortuosities, colors, and presence of spines or boutons. Features 1–9 of Figure 3 were used to produce the results of this study. These features were selected based on our knowledge of neuroanatomy and intuition gained from manual neuron tracing. We carefully examined the decisions we make when faced with branch merging tasks and initially created a list of 17 features that are shown in Figure 3. Features 15 and 16 are not applicable for the OP and L6 datasets as these datasets include grayscale images of axons only. Features 10–14 and 17 were tested but did not improve the performance of the classifiers. This is why the above features (10–17) were left out of the analysis. This is not to say that features 10–17 are not important; they may be useful for other dataset types.</p><p>如图一,即使初始追踪点准确描述神经元几何形状,但它往往不能捕捉到正确的分支的拓扑.为了解决这个问题,我们从中分离各个初始节点的分支和根据神经元形态学的先前知识组合它们成树状结构.为了辩别真假分支节点的通路,不同的分支节点合并脚本在机器学习中优化,通过组合追踪的多样特点信息,这些特点包括分支距离,分支方向,平均亮度,亮度变动,分支厚度,导致弯曲的因素,弯曲,颜色,神经轴突的存在.特征图3的1-9生成本研究的结果.根据我们人工跟踪神经元得到的解剖学与直觉的知识来选择这些特性。我们仔细审核我们所做的决定–对于分支合并任务和初始创建特征图3的17的列表,如图3所示功能15和16不适用于OP和L6数据集,这些数据集只包括轴突的灰度图像。特征图10-14和17进行了测试，但没有提高分类的效果。这也是为什么上述特征图（10-17）被排除分析。这并不是说，具有10-17并不重要;它们可以是用于其他数据集类型是有用的。</p><p>To evaluate different branch merging patterns in the disconnected initial trace we cluster branch terminal points on the basis of their relative distances.<br>为了改善不同分支合并的模式在分离初始追踪,我们在它们相对距离的基础上连接分支末端.<br>For this, we first create an all-to-all connected graph in which nodes represent the branch terminal points. Next, the links between distant nodes (&gt;10sx) are removed, exposing the clusters of nearby branch points.<br>为此,我们首先创造了代表分支节点末端的一个节点的全部连接图形,接下来,距离&gt;10sx的线会被移走,出现临近分支节点的集群.<br>The threshold distance of 10sx was chosen based on two considerations.<br>基于两方面考虑选择了10sx的阈值距离:<br>First, this distance has to be larger than the voxel size (sx) and the size of a typical gap in intensity resulting from imperfect labeling of branches (0 for OP and ~5sx for L6).<br>首先,这个距离必须比三维像素尺寸（SX） 和 在亮度上,由于不好的标记分支得到的一个典型间隙大小（0为OP和〜5SX为L6） 要大.<br>Second the threshold distance has to be smaller than the typical branch length (20sx-50sx for OP and L6).<br>第二,这个阀值距离必须小于典型分支长度(20sx-50sx对于OP和L6).<br>Results of branch merging are not sensitive to the precise value of this parameter in the 5sx–15sx range. Branch merging is examined within each cluster of branch terminal points independently.<br>在精确到5SX-15sx范围内参数,分支合并的结果是不明显的.在每一个独立的分支末端点集群中,分支合并是被检查.</p><p>Within a given cluster, all possible branch merging scenarios are considered (Figure 4A), and the correct merging pattern is determined in a classification framework.<br>在给定的群集中,我们会考虑采用所有可能的分支合并方案（图4A）,和在一个分类框架,去确定正确的合并模式.<br>Clusters containing 2 terminal points lead to two scenarios, i.e., to connect or not to connect the terminal points.<br>包含了两个末端点的多集群将导致两种情况:连接或不连接末端点.<br>Three terminal point clusters result in 5 scenarios, 4 terminal point clusters lead to 15 (Figure 4A), and the number of scenarios increases exponentially with the complexity of clusters (Figure 4B).<br>三个末端点的集群将导致五种结果，四个末端点的集群将导致十五种结果（图4A），和结果的数目与集群的复杂性（图4B）呈指数增大。<br>This exponential increase gives a unique advantage to our classification approach to branch merging.<br>对于进行分支合并的分类,该指数增长提供了一个独特的优势.</p><p>Generally, machine learning applications require large sets of labeled data.<br>一般情况下，机器学习应用需要大量标记数据。<br>Creating such sets can be very time-consuming and, in many cases, impractical.<br>创造这样的集合是非常费时,在许多情况下，不实用。<br>Our training strategy circumvents this problem by exploiting the large numbers of branch merging scenarios.<br>我们的训练策略是利用大量的分支合并方案去规避了这一问题。<br>Labeling the correct branch merging scenario in a single cluster can provide thousands of training examples.<br>在一个集群中提供数以千计的例子去标记一个正确的分支合并方案.<br>Hence, it becomes possible to train the classifier in real time and obtain accurate results by labeling only 10–100 clusters of branch terminal points.<br>因此,在现实中有可能训练出分类器,通过仅仅标记10-100个分类末端点的集群去获取精确的结果.<br>All possible branch merging scenarios are evaluated within a given cluster of branch terminal points.<br>在给定的分支末端节点集群中,所有可能的分支合并的方案都会被评估.<br>Each scenario, i, is characterized by a feature vector xi (Figure 4A) whose components consist of features of the trace that may be important for selecting the correct branch merging scenario (Figure 3).<br>每个方案其特点是一个特征矢量xi（图4A）,其组件包括可能是重要的追踪的特性,对于筛选正确的分支合并方案（图3）。<br>The problem is thus reduced to learning the best set of weights, w, for discriminating between the correct and erroneous scenarios within every cluster.<br>因此,对于如何辨别每个集群中正确还是错误的方案,这个问题被简化为如何得到最好权重W,</p><p><img src="http://i.imgur.com/04skYCn.png" alt="Imgur"></p><p>This formulation leads to another important advantage for the implementation of the classification strategy. Due to the linearity of the problem, Equation (5) can be rewritten as,<br>这公式对于实现分类策略有其他重要优势。由于问题是线性的，方程式如下</p><p><img src="http://i4.buimg.com/567571/5904245d28c853cc.png" alt=""></p><p>resulting in a subtractive normalization of the feature vectors within individual clusters.<br>这导致在独立集群的特征向量的消减归一化。<br>Because branch merging scenarios are only compared within clusters, Equation (6) effectively normalizes for the variations in image intensity and density of neurites across clusters.<br>因为分支合并方案只能在集群中比较。方程6可以高效归一对于图像亮度和集群中神经的密度的变化<br>The classification problem of Equation (6) is solved with sign-constrained perceptron (Engel and Broeck, 2001) or SVM classifiers (Wang, 2005), which were modified to be able to account for the relative importance of some training examples.<br>用sign-constrained perceptron (Engel and Broeck, 2001) or SVM classifiers (Wang, 2005)可以解决方程6的分类问题，这被修改，可以解释一些训练例子的相对重要性。<br>The sign-constrained perceptron algorithm was previously described in Chapeton et al. (2012):<br>sign-constrained perceptron算法以前在Chapeton et al. (2012)如下描述：</p><p><img src="http://i1.buimg.com/567571/8c689f5fb86160cc.png" alt=""></p><p>where w is the weight vector of the perceptron classifier, Δxμ is the difference between the feature vectors for the erroneous merger μ and the correct merger from the same cluster,<br>w表示感知分类的权重向量， Δxμ表示在相同集群中错误合并μ和中正确合并分支的特征向量不同，<br> N is the number of features (9 features were used in this study), and m is the number of comparisons made (total number of scenarios minus number of clusters).<br>N指的是特性数字（在该研究中9特征），和m是压缩模式中的数字(总方案除以集群数量)。<br>The value of the parameter gk can be set to −1 or 1, constraining the corresponding weight, wk, to be negative or positive, or set to 0, in which case the weight is unconstrained.<br>参数gk的值设置为-1或者1，限制相应的权重，wk，加强或减弱，或者设置为0，使得权重无限制。<br>Because larger distances, overruns, and offsets of terminal points (see Figure 3) decrease the likelihood that branches should be merged, the weights of these features were constrained to be positive.<br>因为更长距离，末端点的偏移或超出（见图3），减少了分支该合并的可能，这些特征权重是趋向于加强。<br>In addition, the weight associated with the number of free terminal points was constrained to be positive to promote branch merging.<br>此外，权重因自由末端的数量的提高，而改善分支合并。<br>All other weights were left unconstrained as we did not have clear motivation for doing otherwise. Hence, g = (1,1,1,0,0,0,0,0,1)T was used in this study.<br>其他权重不限制，因为我们没有明确动机去做，除非，g=（1,1,1,0,0,0,0,0,1）T会被使用在这个研究中。<br>Parameter κ is referred to as the perceptron robustness (analogous to SVM margin). Increasing κ should initially improve the generalization ability of the perceptron,<br>参数k引用作为健壮性(类似于SVM的边缘)。K的增加应该最初改善感知器通用能力。<br>but as the perceptron fails to correctly classify a progressively increasing number of training examples, this generalization ability should decrease.<br>但由于当训练样本数增加，感知器无法正确分类，这种通用能力应该减少。<br>We used the leave-one-out cross-validation scheme to examine this trend. In this scheme, training is done on all but one labeled example, and the remaining example is used for validation.<br>我们用了差一法、交叉验证去检验这个趋势，所有训练样本完成后，除了一个用来标记，其余都用于验证。<br>In Figure 5 each branch merging cluster was used once for validation and the results were averaged. Figure 5A shows that there is a large range of κ for which the perceptron performs reasonably well for both L6 and OP datasets.<br>在图像5，每一个分支合并集群用于验证，结果是平均的。图5a显示当有大量κ，感知器的表现相当不错，L6和OP的数据集。<br>The value of κ was set to 1 throughout this study.<br>在本研究，κ的值被设置为1。</p><p><img src="http://www.frontiersin.org/files/Articles/81880/fnana-08-00037-HTML/image_m/fnana-08-00037-g005.jpg" alt=""><br>Figure 5. How to choose best classification parameters. (A) Leave-one-out cross-validation error-rate as function of the perceptron robustness parameter, κ [see Equation (7)].<br>图5,如何选择最好的分类参数.归一法 交叉验证错误几率作为感受器健壮性功能的参数,κ [见方程(7)].<br>(B) Same error-rate as function of the SVM parameter, C [see Equation (9)].<br>相同错误几率作为SVN功能的参数,C [见方程(9)].<br>The inset shows how SVM margin, M, depends on C. Solid and dotted lines show the results for the OP and L6 datasets respectively.<br>这插入物显示了SVN是怎样留白,M,依赖于C.实线与点状线分别显示了OP与L6结果集的实验结果.<br>Large empty circles indicate the parameter values that were used throughout this study, κ = 20 and C = 220.<br>大空心环表明了这个研究始终使用这个参数值,K=20和C=220.</p><p>The sign-constrained perceptron problem of Equation (7) was solved by using a modified perceptron learning rule (Engel and Broeck, 2001):<br>使用更变后的感受器学习规则解决了该方程式7的符号约束感受器问题(Engel and Broeck, 2001):</p><p><img src="http://i1.buimg.com/1949/4418dd7024af8a6e.png" alt=""></p><p>Δw=θ(κN−1NwTΔxμ)1NΔxμ wk=wkθ(wkgk), k=1,2,…,N    (8)</p><p>In this expression, Δw denotes the change in the perceptron weight vector in response to presentation of the training example μ;<br>在这个表达式中, Δw表明在感受器权重向量的改变将影响训练例子μ的感受器.<br>θ is the Heaviside step function, which is defined to be 1 for non-negative arguments and zero otherwise.<br>θ是海维赛德阶跃函数,是定义为1,为了非负参数与0.<br>The step functions in Equation (8) ensure that training is not done on learned examples, and that the perceptron weights violating the sign-constraints are set to zero at every step of the algorithm.<br>该阶跃函数在方程8确保了这个训练是没有在已经学习过的例子中做过,在算法中的每一步中,当感受器违反符号约束,权重被设为0.<br>Perceptron weights are updated asynchronously by training on examples, μ, that are drawn from the set of all examples with probabilities proportional to user-defined cluster weights, Qμ.<br>感受器权重是随着例子训练不断同步更新, μ,从所有例子中有概率比例对于用户定义集群权重得到,Qμ.<br>All cluster weights are initially set to 1 and can be modified by the user to increase the probabilities with which examples from some clusters come up for training.<br>所有集群权重初始化设置为1,可以被用户修改,增加概率,在训练中出现一些集群的例子.<br>This makes it possible to enforce learning of certain rare branch merging topologies.<br>这尽可能使得可学习某些特殊分支合并的拓扑结构.<br>Though user-defined cluster weights may be used to improve the outcome of training, this feature was not examined in the present study to avoid subjectivity associated with different choices of Qμ.<br>通过用户定义的集群权重可以用于改善训练的输出结果,这个特性是没有审核在现在的研究的,为了避免主观联系Qμ的不同选择.<br>An SVM classifier can also be used to solve the system of inequalities in Equation (6). To incorporate the used-defined cluster weights, Qμ,<br>在方程式6,一个SVN分类器可以被用于解决系统的不均等.去组成用户定义的集群权重,Qμ,<br>we modified the standard formulation of the SVM problem (Wang, 2005), and in this study maximize the following dual Lagrangian function in order to obtain the SVM weight vector w:<br>我们修改SVN问题(Wang,2005)的标准参数,和在该研究中,最大化以下双拉格朗日函数去获取SVN权重向量w:</p><p><img src="http://i4.buimg.com/1949/25b7129b0348d2ba.png" alt=""></p><p>In these expressions, l is the number of SVM support vectors and C is the SVM margin (see the inset in Figure 5B).<br>在这表达式中,l是SVN支持向量的数量,C是SVN留白(见插入物在图5B).<br>Similar to the perceptron robustness, there is a large range of values of C for which the SVM produces reasonably good generalization results for both datasets.<br>类似于感受器健壮性,这大范围的C值可以使得SVN生产出合理而好的通用结果,对于这两个数据集.<br>C = 220 was used to produce results of this study. Again, all used-defined cluster weights, Qμ, were set to 1 during training.<br>C=220被用于产出该研究的结果,再次,所有用户定义的集群权重 Qμ,都被设为1在训练期间.</p><h3 id="Active-Learning-Strategy"><a href="#Active-Learning-Strategy" class="headerlink" title="Active Learning Strategy"></a>Active Learning Strategy</h3><h3 id="主动学习策略"><a href="#主动学习策略" class="headerlink" title="主动学习策略"></a>主动学习策略</h3><p>In this section we describe a pool-based sampling approach (Lewis and Gale, 1994) that can be used to actively train the Perceptron and SVM classifiers on branch merging examples.<br>在这一部分,我们描述一个基于池抽样方法 (Lewis and Gale, 1994),用于积极训练感受器和SVM分类器在分支合并的例子中.<br>In this approach the user selectively draws queries from the pool of all branch merging clusters based on the value of the confidence measure:<br>这这个方法,用户并不普遍画出问题从所有分支合并集群池中,基于信任的测量值:<br>Confidence=e−wTxcorrect merger/T∑i∈allmergerse−wTxi/T    (10)</p><p>This measure assigns low confidence values (in the 0–1 range) to clusters in which the erroneous merging scenarios are located close to the decision boundary defined by w.<br>在这个测量分配低可信值(在0-1范围)对于使用错误合并方案的集群接近判定边界由w定义.(err)<br>Parameter T controls the spread of confidence values but does not affect their order.<br>参数T包含了可信值的范围除了不影响他们的规则.<br>This parameter was set to 1 throughout the study. Training can be performed after labeling a single or multiple low confidence clusters, and the confidence measure is updated after each training step.<br>在该研究中,这个参数是设定为1.训练可以实施,在边界单个或多个低可信集群和可信测量是被更新的在每一步训练后.<br>It is absolutely essential that clusters in which the correct merging scenario cannot be identified with high certainty should not be used for training,<br>绝对的是,高度肯定的正确合并方案不能被识别的集群是不能作为训练样本的.<br>as a small number of errors in the labeled set may significantly worsen the performance of classifiers.<br>即使是作为小错误在标记集群中也许会极大地使得分类器的性能下降.</p><h3 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h3><h3 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h3><p>The methodology described in this study is implemented in the NCTracer software for automated tracing of neurites.<br>在本研究中,该方法论以NCTracer软件进行自动追踪神经进行演绎.<br>This methodology consists of two major parts—initial tracing and branch merging.<br>改方法论包含了两个主要部分初始化追踪和分支合并部分.<br>In the first part, an initial trace is created by using the Voxel Coding (Zhou et al., 1998; Zhou and Toga, 1999; Vasilkoski and Stepanyants, 2009) or the Fast Marching (Cohen et al., 1994; Cohen and Kimmel, 1997; Sethian, 1999; Mukherjee and Stepanyants, 2012) algorithm, and optimized to ensure that the trace, including its branch and terminal points, conforms well to the intensity in the underlying image (see the Methods section for details).<br>在第一部分,一个初始追踪使用三维像素编码(Zhou et al., 1998; Zhou and Toga, 1999; Vasilkoski and Stepanyants, 2009) 或是快速行进算法(Cohen et al., 1994; Cohen and Kimmel, 1997; Sethian, 1999; Mukherjee and Stepanyants, 2012) 所创造,优化去确保该追踪,包括它的分支和末端点,确保亮度在下层图像中(见方法部分的细节).<br>Below we examine the initial traces from two very different dataset types: axons of single olfactory projection neurons from Drosophila (OP dataset, n = 9 image stacks) (Jefferis et al., 2007) and axons of multiple layer 6 neurons imaged in layer 1 of mouse visual cortex (L6 dataset, n = 6 image stacks) (De Paola et al., 2006).<br>我们从两个差异大的数据集中审核初始追踪点:来自果蝇的单嗅觉轴突神经工程(OP dataset, n = 9 image stacks) (Jefferis et al., 2007)和小鼠视皮层一层的多层6神经轴突 (L6 dataset, n = 6 image stacks) (De Paola et al., 2006).<br>These datasets were featured at the DIADEM challenge (Brown et al., 2011) and serve as benchmarks for automated reconstruction algorithms.<br>对于自动重建算法,这数据集的特色是在DIADEM挑战中(Brown et al., 2011)作为标准.<br>Figures 1A,B show representative image stacks from the OP and L6 datasets.<br>图1A,B显示了代表图像栈来自OP和L6数据集.<br>The initial traces are superimposed on the maximum intensity projections of the image stacks, and are slightly shifted for better visibility.<br>初始追踪是成阶层状的,预测在图像栈中的最大亮度,为了更好表现,稍微改变.<br>As can be seen, these initial traces accurately represent the geometry of neurites contained in the image stacks.<br>这些初始追踪精确表达了在图像栈中的神经的几何形状.<br>However, a closer examination of the L6 trace topology reveals numerous erroneously merged (stolen) branches.<br>然而,更接近L6追踪拓扑的检查揭露了更多错误的合并的神经分支.<br>Such errors in the initial trace often occur when the neurites belonging to different trees appear to be in contact due to poor z-resolution or due to high density of labeled structures.<br>例如错误在初始追踪时常发生,当属于不同树的神经,彼此联系,由于匮乏的z解决方案或是由于标记结构的高密度.<br>Presence of these topological errors becomes evident after labeling distinct tree structures with different colors (Figure 1C).<br>在用不同颜色标记树清晰的结构后,这些拓扑学错误的出现变成明显.<br>The second part of our automated tracing algorithm uses a machine learning approach that actively learns the morphology of neurites in an attempt to resolve the errors present in the initial trace (see Figure 1D).<br>我们自动追踪算法的第二部分用了机器学习方法,主动学习神经的形态,尝试去解决初始化追踪出现的错误(见图1D).</p><h3 id="Comparison-of-Automated-Initial-Traces-and-Manual-User-Traces"><a href="#Comparison-of-Automated-Initial-Traces-and-Manual-User-Traces" class="headerlink" title="Comparison of Automated Initial Traces and Manual User Traces"></a>Comparison of Automated Initial Traces and Manual User Traces</h3><h4 id="比较自动化初始追踪和手工用户追踪"><a href="#比较自动化初始追踪和手工用户追踪" class="headerlink" title="比较自动化初始追踪和手工用户追踪"></a>比较自动化初始追踪和手工用户追踪</h4><p>Below we evaluate how well automated and manual traces capture the layout (geometry) of the neurites in the image stack, as well as how well they represent the morphology of branching tree structures (topology).<br>在图像栈中,评估自动化和手工追踪获取神经形态布局哪个更好,也就是他们谁更能代表分支树结构的形态(拓扑).<br>Similar comparisons have been carried out in other studies (Gillette et al., 2011a; Choromanska et al., 2012;Mayerich et al., 2012).<br>相似的比较已经得到在其他研究成果中.(Gillette et al., 2011a; Choromanska et al., 2012;Mayerich et al., 2012).<br>Each OP and L6 image stack was traced automatically using the Fast Marching algorithm as well as manually by three trained users.<br>每一个OP和L6图像栈是自动追踪用快速行进算法也让三个熟练用户手工追踪.<br>Figure 6A shows an example of the resulting four traces of a single OP stack. Inevitably, imperfect labeling and limited resolution of optical microscopy lead to uncertainties in tracing.<br>图6A显示出单个OP栈的4个追踪的例子结果.不可避免的,不完美的标记以及光学显微镜的缺陷导致不可信的追踪.<br>Trained users often resolve such uncertainties differently from one another, and hence no single trace can be viewed as a gold standard.<br>熟练用户常常分解例如不能确定的不同,因此没有单追踪作为黄金标准.<br>Thus, we had to first establish quantitative measures describing the baseline inter-user variability, and only then evaluate the performance of the automated tracing algorithm in comparison to this baseline.<br>因此,我们不得不首次建立定量测量去描述基线用户间变异性,和评估自动追踪算法的性能的比较标准.<br>To this end, each manual trace was chosen to be the gold standard and compared to the automated trace and the remaining two manual traces. This led to 6 inter-user and 3 automated-to-user trace comparisons for each stack.<br>最后,每一个手工追踪最终都被选择为黄金准则,去比较自动追踪算法,和剩余两个手工追踪.对于每个栈来说,有了6个用户间和3个机器与人工的追踪比较.</p><p><img src="http://www.frontiersin.org/files/Articles/81880/fnana-08-00037-HTML/image_m/fnana-08-00037-g006.jpg" alt=""><br>Figure 6. Assessing the quality of automated traces. (A) Three manual traces (green, blue, and yellow) and one automated trace (red) are superimposed on a maximum intensity projection of an OP neuron.<br>图6,通过自动化的才能,(A)三个手工用户(绿,蓝,黄)和一个自动追踪(红)是成阶层在op神经元的最大亮度中.<br>The traces are staggered upward for better visibility. The inset shows a zoomed view of the boxed region. Scale bar is 20 μm.<br>该追踪是错开排列的为了更好显示.该插图显示了盒范围的升视角.比例尺是20μm.<br>(B) Several geometrical and topological features are used to compare traces. Gold standard trace (yellow) and test trace (blue) are shown.<br>(B)比较追踪是通过几个几何学和拓扑学的特点.黄金准则(黄)和测试追踪(蓝)如图.<br>Both traces are composed of nodes connected by edges of length d. Nodes on these traces are referred to as corresponding nodes if they are located within distance h of each other (d &lt;&lt; h).<br>追踪都是由长度d边缘连接的节点组成的.如果节点位于相距h范围内,追踪的节点被称为对应的节点.<br>Circles highlight false negative and false positive branch and terminal points. (C–E) Automated traces reliably capture the geometry of neurites.<br>高亮圆表示错误的分支与末端节点.(C-E)自动追踪确实获取了神经的形态.<br>Nine OP axons were reconstructed with NCTracer, first automatically and then manually by three trained users.<br>9个OP轴突由NCTracer重建,首先自动然后由三个受训用户手工重建.<br>The probability densities for distances between the corresponding trace nodes (C), terminal points (D), and branch points (E) were used as metrics for geometrical comparisons.<br>这个可能性密度距离在相对应追踪节点(C),末端节点(D),和分支节点(E)作为材料进行形态比较.<br>Red lines show the results of automated-to-user trace comparisons. Here, all user traces for every stack were used one by one as the gold standard, leading to 27 automated-to-gold standard trace comparisons.<br>红线表示机器与人工追踪的比较结果.所有用户追踪对于每一个栈都一比一作为黄金准则，有27机器与黄金准则追踪的比较。<br>The results were pooled. Blue lines show similar results based on 54 user-to-user trace comparisons.<br>这结果是贫乏的。蓝线表示基于54个用户与用户的追踪比较的相似的结果<br>(F–H) Automated traces accurately represent the topology of OP neurons. Three topological measures were compared: false positive/negative trace lengths (F), numbers of false positive/negative terminal (G) and branch (H) points.<br>（F-H）自动追踪精确代表了OP神经数据集的拓扑结构。比较三个拓扑结果的测量得出：错误分支与末端节点(F)的长度，错误分支与末端节点（G）与分支节点（H）的数量。<br>Red and blue bars show the fractions of automated-to-user (n = 27) and user-to-user (n = 54) comparisons for different error types.<br>红与蓝条显示了机器与用户(n=27)与用户对用户(n=54)的部分比较有不同的错误类型。<br>The fractions for false positive and false negative errors are indicated with the bars above and below the x-axes.<br>错误的分支与末端节点的分数用高于x轴的条与低于x轴的条来表示。</p><p>To ensure the uniformity of the reconstructed dataset, all traces were subdivided into segments of equal length (d = 0.25 voxels).<br>为了确保重建数据集的一致性,所有追踪再分成等长的片段(d=0.25voxels).<br>To compare a pair of traces (a test trace and a gold standard trace) we perform a bi-directional nearest neighbor search to find corresponding nodes,<br>为了比较两者的追踪(测试的追踪和黄金准则的追踪)我执行双流向最近邻接搜索去发现相应的节点,<br>i.e., nodes on the two traces separated by less than h = 10 voxels (see Figure 6B).<br>在两个追踪,节点被分开于少于十个体积像素(见图6B).<br>A node in the test trace which has (does not have) a corresponding node in the gold standard trace is referred to as a true (false) positive node.<br>在测试追踪中,在黄金准则追踪线路,有一个相对应的节点的一个节点是作为一个真的积极节点.<br>A node in the gold standard trace for which there is no corresponding node in the test trace is referred to as a false negative node.<br>在黄金准则追踪中的,没有相对应的一个节点在测试追踪中作为一个假的消极节点.<br>Short terminal branches (less than 12 voxels) and dim branches (average intensity less than 0.12) were excluded from the comparisons.<br>短末端分支(少于12体积像素)和暗淡分支(平均亮度少于0.12)是被排除于比较的.<br>Results of the geometrical comparisons between automated initial traces and manual traces for the OP image stacks are shown in Figures 6C–E.<br>在OP图像栈,自动化初始追踪与手工追踪的几何学比较结果显示在图6C-E上.<br>The plots show probability densities of distances between corresponding nodes, corresponding branch points, and corresponding terminal points for both inter-user (blue lines),<br>计划显示了距离上可能的密度在相对应的节点,相对应的分支点和相对应的末端节点对于两者的内部用户(蓝线).<br>as well as automated-to-user comparisons (red lines). The geometrical precision of the automated and manual traces is evidenced by the fact that 95% of distance values lie below 2.3 voxels in Figure 6C, 7.3 voxels in Figure 6D,<br>和机器与用户的对比(红线).这个自动化追踪和手工追踪的几何精密是由事实来评估的:95%的距离值都小于2.3体积像素在图6C,7.3体积像素在图6D,<br>and 6.6 voxels in Figure 6E. More importantly, the difference between mean distances for the inter-user and automated-to-user comparisons (0.19, 0.51, and 0.65 voxels respectively) is smaller than the resolution of the image,<br>和6.6体积像素在图6E.更重要的是,用户间和机器与用户之间的比较的真实距离的不同时远小于图像的分辨率的.<br>and thus should have little bearing on trace dependent measurements. Similar conclusions were drawn from the geometrical comparisons of automated and manual traces of the L6 dataset (Figures 7A–C).<br>因此,应该有小误差在追踪中使用的尺寸.相似的结论由L6数据集中机器与手工追踪形态学比较中可以得出(图7A-C).</p><p>FIGURE 7<br><img src="http://www.frontiersin.org/files/Articles/81880/fnana-08-00037-HTML/image_m/fnana-08-00037-g007.jpg" alt=""><br>Figure 7. Assessment of initial traces of multiple neuron axons. Six L6 image stacks were reconstructed manually and automatically with NCTracer (see Figure 6 legend for details).<br>图7,多神经轴突的初始化追踪的评估.6个L6图片栈是由NCTracer手工和自动化重建的.<br>(A–C) Automated traces reliably capture the geometry of neurites. The probability densities for distances between the corresponding trace nodes (A),<br>(A-C)自动化追踪可靠地捕获神经的形态.在相对应追踪节点(A)之间的距离有可能性密度,<br>terminal points (B), and branch points (C) were used as metrics for geometrical comparisons. Red lines (n = 18) and blue lines (n = 36) show the results of automated-to-user and user-to-user trace comparisons.<br>末端点(B)和分支点(C)是作为几何比较的指标.红线(n=18)和蓝线(n=36)显示了自动化与用户和用户与用户追踪比较的结果.<br>(D–F) While the automated traces capture the geometry of the neurites well, they contain a markedly large number of false positive branch points (F).<br>(D-F)当自动追踪捕获神经形态学时,它们包含了一个极大数量的假正分支点(F).<br>These topological errors result from erroneous mergers of distinct axons that pass in close proximity of one another.<br>这些拓扑错误是由于在彼此接近的且明显轴突中错误合并.</p><p>Topological errors that occur due to incorrectly merged branches are more difficult to detect and can be detrimental to circuit reconstruction projects.<br>发生拓扑错误是由于检测错误的分支合并是比较困难的,还可能对线路重建项目不利.<br>Three measures were selected to quantify the extent of such errors: false positive/negative trace lengths, numbers of false positive/negative terminal points, and numbers of false positive/negative branch points.<br>使用了三项措施去量化这些错误的程度:假正向/负向的追踪长度,假正向/负向的末端节点的数量,以及假正向/负向的分支节点的数量<br>The results of comparisons for the OP dataset (Figures 6F–H) show that similar numbers of topological errors were made by the algorithm and the users, and these numbers were generally small (less than one false positive/negative branch or terminal point per stack).<br>(图6F-H)对于OP数据集的比较结果显示拓扑错误的相似数量由于算法和用户造成的,这些数字通常小(小于每个栈中的一个假正向/负向分支或末端节点).<br>For the L6 image stacks, the mismatches in length for the automated and manual traces were similar (Figure 7D), indicating that the automated algorithm performed as well as trained users in tracing the majority (in terms of length) of labeled structures.<br>(图7D)对于L6图像栈,对于机器和手工追踪的长度错配是相似的,表明了自动算法的表现与熟练追踪标记结构(长度方面)的用户一致.<br>However, in contrast to manual traces, automated traces contained more false positive/negative terminal points (Figure 7E) and markedly larger number of false positive branch points (Figure 7F).<br>然而,与手工追踪相比,自动化追踪包含了更多假正向/负向末端节点(图7E)和更多的假正向分支节点(图7F).<br>The former errors result from branches that are broken due to imperfect labeling, while the latter arise from a specific artifact of the Fast Marching algorithm, i.e., merging nearby, but distinct branches.<br>前者错误是因为分支断裂由于不完美的标记,而后者是从快速行进算法的特定人工品,即,合并附近的分支但不同的分支结果.<br>In particular, lower z-resolution of an image stack makes such mergers more prevalent, leading to larger numbers of false positive branch points.<br>尤其,z轴的低分辨率的图像栈使得这种合并更加普遍,导致了更大数量的假正向分支节点.</p><h3 id="Active-Learning-of-Branching-Morphology-of-Neurites"><a href="#Active-Learning-of-Branching-Morphology-of-Neurites" class="headerlink" title="Active Learning of Branching Morphology of Neurites"></a>Active Learning of Branching Morphology of Neurites</h3><h3 id="轴突分支形态的主动学习"><a href="#轴突分支形态的主动学习" class="headerlink" title="轴突分支形态的主动学习"></a>轴突分支形态的主动学习</h3><p>To resolve the above mentioned topological errors, branches of the initial trace were disconnected from one another and merged into tree-like structures in an active learning approach described in the Methods section.<br>为了解决上述拓扑错误,初始追踪的分支是彼此断开的,在本文描述的主动学习方法中合并进类似树的结构.<br>Briefly, the positions of branch and terminal points were clustered based on distance, and branch merging was performed within every cluster independently (see Figure 4).<br>简单点,分支节点和末端节点的位置是基于距离进行聚群的,和独立地完成分支合并在每个集群中(见图4).<br>Perceptron and SVM classifiers were designed and trained online to accomplish the branch merging task generating the final traces of the OP and L6 image stacks.<br>感知器和SVM分类器被设计和在线训练去完成分支合并任务生成OP和L6图像栈的最终追踪.<br>To assess the performance of the classifiers, their generalization error rates were monitored as functions of the number of training examples.<br>为了评估分类器的性能,他们普遍错误比例作为训练实例数量的函数进行监测的.<br>Figures 8A,B compare the performance of the classifiers trained on randomly selected branch merging examples with that of classifiers trained in an active learning approach.<br>图8A,B 比较分类器的性能 训练在随机选择的分支合并例子的分类器 与 用主动学习方法训练的分类器<br>The plots show that the active learning approach provides a clear advantage in terms of the number of training examples required to reach a given error rate.<br>该图表明主动学习方法提供了清晰的优势,在达到给定的错误比率的训练例子的数量上.<br>For each dataset, error rates of less than 5% were achieved by both classifiers with less than 40 actively chosen training examples.<br>对于每一个数据集,小于40训练例子的分类器可以达到少于5%的错误率.<br>The rapid decline of the generalization error rate validates our choice of features used for the branch merging task (see Figure 3).<br>普通错误比率的迅速下滑证明了我们的选择–用于分支合并任务的特性(见图3).<br>As expected, trained SVM and perceptron classifiers established nearly identical decision boundaries, as judged by the distance between their normalized weight-vectors (0.29 for OP and 0.10 for L6).<br>如预期,受训的SVM分类器和感受器建立了几乎相同的决策边界,通过归一化权重矢量之间的距离来判断.<br>In contrast, between-dataset distances were larger (0.63 for perceptron and 0.63 for SVM), indicative of the fact that classifiers were able to capture dataset specific morphological information.<br>与此相反,数据集之间的距离[差距]是增大的(0.63的感受器和0.63的SVM),表明了分类器是可以捕获数据集特定形态信息的事实.</p><p>FIGURE 8<br><img src="http://www.frontiersin.org/files/Articles/81880/fnana-08-00037-HTML/image_m/fnana-08-00037-g008.jpg" alt=""><br>Figure 8. Online training can be used to reduce the numbers of topological errors present in initial traces.<br>图8 在线训练可以用于减少拓扑错误率在初始化追踪时的数量<br>(A) Generalization error-rate as function of the number of training clusters for the perceptron classifier.<br>(A) 普通错误比率作为训练感受分类器集群的功能指标.<br>Black lines (mean) surrounded by gray margins (standard errors) show the results of random training.<br>黑线(实线)由灰色边框(标准错误)显示随机训练的结果.<br>For each number of training clusters, training sets were generated at random 1000 times. Training was performed on each set of clusters, while testing was done on the remaining clusters.<br>为每一个集群的训练,训练集随机生成1000次,在每个组的集群进行培训,而剩余的集群用于测试.<br>Results for all 1000 experiments were averaged. Solid and dotted lines show the results for the OP and L6 datasets respectively.<br>平均1000次的实验结果.实线和虚线分别显示了OP和L6的数据集.<br>Red lines show the corresponding results for active training experiments. (B) Same for the SVM classifier.<br>红线显示了主动训练实验的结果.(B)与SVM分类器一样.<br>(C) The number of false positive branch points present in the initial trace of L6 dataset (Figure 7F) is greatly reduced by the branch merging algorithm.<br>(C)目前在L6数据集(图7F)初始化追踪时,通过分支合并算法大量减少了假正向分支节点.<br>(D) The sum of false positive and false negative branch point errors is an increasing function of length density of labeled neurites.<br>(D)假正向或假负向分支节点错误的总数是对标记的神经元轴突的长度密度的增函数.<br>Length density is calculated as the average length of neurites traced by the users divided by the image stack volume. Error-bars indicate the range of branch point errors.<br>长度密度的计算方法是 用户追踪的神经的平均长度 除以图像栈体积.<br>Automated tracing algorithm performs as well as trained users when the density of labeled neurites is low (&lt;0.003 μm−2).<br>自动追踪算法的性能与与用户追踪在标记神经的亮度低时(&lt;0.003μm−2).</p><p>Geometry and topology of the final automated traces produced by the branch merging algorithm were compared to the user traces in the manner described in Figures 6, 7.<br>最终自动追踪的几何和拓扑由用户追踪的方式(如图6,7所说)用分支合并算法生成.<br>No significant geometrical changes resulted from automated branch merging. This was expected, as trace modifications that accompany branch merging are confined to very local regions in the vicinity of branch or terminal points.<br>没有显著的形态改变是由于自动分支合并.如所期望的,作为追踪伴随着分支合并是被非常局限的区域所限制而修改,在分支或末端附近.<br>In addition, automated branch merging did not alter the topology of initial traces of OP neurites.<br>更多的,自动分支合并不会更改OP神经初始化追踪的拓扑.<br>The reason is that the initial traces of these morphologically simple structures did not contain significant topological errors in the first place (Figures 6F–H).<br>原因是在第一个地方,这些形态简单结构的初始追踪不会包含显著的拓扑错误(图6F-H).<br>As for the topology of L6 traces, no significant changes were observed in false positive/negative lengths (Figure 7D) and terminal point numbers (Figure 7E).<br>至于L6追踪的拓扑,在假正向/负向长度(图7D)和末端点数字(图7E),没有观察到显著的改变.</p><p>As was intended, automated branch merging greatly reduced the number of false positive branch points present in the initial traces (Figure 8C vs. Figure 7F).<br>正如预期的,自动分支合并大量减少了在初始化追踪时的假正向分支的数量(图8C与图7F).<br>Though the reduction in the number of false positive branch points was large (about two-fold), the branch merging algorithm failed to achieve the level of user performance (Figure 8C).<br>通过假正向分支点数量的减少(大概两倍),分支合并算法没有达到用户性能的级别(图8C)<br>To examine the reason behind this disparity we plotted the sum of false positive and false negative branch point errors for every L6 stack as function of length density of neurites contained in the stack (Figure 8D).<br>检查这种差距背后的原因是，我们绘制的假正向和假负向的分支点误差作为每L6栈作为包含在该栈的神经的密度长度的指标(图8D).<br>The length density is defined as the total length of traced neurites (in μm) divided by the stack volume (in μm3) and was calculated for each image stack by averaging over all user traces.<br>该长度比重被定义作为追踪神经的总长除以该栈体积(μm3单位)和被计算每个图像栈平均覆盖所有用户的追踪.<br>These comparisons show that in every stack the branch merging algorithm substantially reduced the total number of errors present in the initial trace.<br>这些比较显示了每一个栈,分支合并算法本质上都是减少初始化追踪的错误数量.<br>What is more, when the density of labeled neurites was small (less than 0.003 μm−2, e.g., Figure 1D), the resulting final automated traces were on par with user reconstructions.<br>此外,当标记神经的密度是小的(少于than 0.003 μm−2 图1D),最终自动化追踪的结果等同于用户重建.</p><h3 id="Comparisons-with-Other-Automated-Tracing-Tools"><a href="#Comparisons-with-Other-Automated-Tracing-Tools" class="headerlink" title="Comparisons with Other Automated Tracing Tools"></a>Comparisons with Other Automated Tracing Tools</h3><h3 id="与其他自动追踪工具比较"><a href="#与其他自动追踪工具比较" class="headerlink" title="与其他自动追踪工具比较"></a>与其他自动追踪工具比较</h3><p>The geometrical and topological measures used to evaluate the quality of automated traces were also used to compare the performance of NCTracer, Vaa3D (Xiao and Peng, 2013), and NeuronStudio (Rodriguez et al., 2009).<br>几何和拓扑测量用于评估自动追踪的质量,比较NCTracer,Vaa3D,NeuronStudio<br>To this end, automated traces of OP and L6 image stacks were obtained with Vaa3D and NeuronStudio. We visually inspected these traces and varied the software parameters to achieve good coverage and performance.<br>为此,OP和L6图像栈的自动追踪是由Vaa3D和NeuronStudio所获得的.我们视觉上检查这些追踪和验证软件参数是否达到最佳覆盖和性能.<br>Inter-user and automated-to-user comparisons were performed as previously described. To evaluate the geometry of automated traces we calculated the mean distances between corresponding nodes and corresponding terminal and branch points.<br>用户间和机器与用户间比较是如前所述.评估自动化追踪的几何,我们计算相对应的节点和相对应的末端节点和分支节点之间的真实距离.<br>To assess the topology of automated traces, we obtained the Miss-Extra-Score (MES) for trace length and for the numbers of terminal and branch points (Xie et al., 2011).<br>评估自动追踪的拓扑,我们获取了MES为了跟踪长度,和末端节点和分支节点的数量<br>Trace MES is defined as the ratio of the gold standard length reduced by the false negative length to the gold standard length increased by the false positive length.<br>追踪MES是定义作为黄金准则长度的范围,减少假负向长度,到黄金准则长度,增加假正向长度<br>Terminal and branch point MES are defined in a similar manner. The results of these comparisons are shown in Table 1.<br>末端节点和分支节点MES是定义在相似的方式.这些比较结果展示在表1.</p><p><img src="http://www.frontiersin.org/files/Articles/81880/fnana-08-00037-HTML/image_m/fnana-08-00037-t001.jpg" alt=""><br>Smaller distance and higher MES indicate greater affinity between test and gold standard traces.<br>当距离越小,MES越高,说明它与黄金准则追踪越接近.<br>Table 1 shows that all automated tracing tools were able to capture trace geometry and topology of single OP axons reasonably well.<br>表1说明了所有自动追踪都可以正常获取到单OP轴突的形态和拓扑结构.<br>The advantage of the branch merging strategy proposed in this study becomes evident from examining the values of topological measures for L6 stacks, which contain multiple axons.<br>在包含多神经的L6栈的拓扑测量审核过程,分之合并策略优势变得明显.<br>According to these measures, NCTracer significantly outperforms other software. And in general, all geometrical and topological measures of NCTracer are closest to the inter-user measures.<br>根据这些测量,NCTracer很明显比其他软件好.总的来说,NCTracer在所有形态和拓扑测量中最接近用户间的测量.<br>Table 1 also shows a trade-off between the quality of automated traces and tracing time.<br>表1也显示了在自动追踪的质量与追踪时间的权衡.<br>Vaa3D and NeuronStudio are 15–20 fold faster than NCTracer.<br>Vaa3D 和 NeuronStudio 是都快于NCTracer 15到20个折叠.<br>We do not view this as a major drawback because tracing of single stacks with the current version of NCTracer can be easily performed on modern day workstations,<br>不将速度作为主要确定因为用最新版本的NCTracer单栈追踪可以很容易在现代工作站中运行.<br>while high-throughput projects could still be carried out on computer clusters.<br>而高通量工程还可以在计算机集群中运行.</p><h3 id="Discussion"><a href="#Discussion" class="headerlink" title="Discussion"></a>Discussion</h3><h3 id="讨论"><a href="#讨论" class="headerlink" title="讨论"></a>讨论</h3><p>Much of our understanding of brain structure and function is derived from quantitative analyses of neuron shapes.<br>许多我们对大脑结构和功能的理解是起源于我们队神经形态上的定量分析.<br>Researchers routinely utilize partial or complete single cell reconstructions, as well as reconstructions of multiple cells often spanning several stacks of images in order to address various questions.<br>为了解决各种各样的问题,研究者常规利用部分或完全的单细胞重建,也多细胞重建常常生成图形栈.<br>Single cell reconstructions are often used in cell classification and comparative neuroanatomy studies, theoretical studies of neuron shapes, and detailed computational models of intracellular activity.<br>单细胞重建常常用于细胞分类和神经解剖学比较,神经形态的理论研究和细胞活性的精密计算模型.<br>Single cell reconstructions are frequently pooled in silico to simulate structural connectivity of local neural circuits.<br>单细胞重建常常汇集在硅肺去模拟局部结构上的神经环的连通性.<br>Reconstructions of multiple labeled cells are used for the analyses of synaptic connectivity in local circuits, in vivo studies of circuit plasticity, and large-scale brain mapping projects.<br>多标记细胞重建是用于在局部系统的突触的连通性的分析中,在体内系统可塑性研究,和大规模脑映射项目.<br>There is no doubt that automating the tracing process will advance these studies, significantly increasing their throughput and eliminating the biases and variability associated with manual tracing.<br>毫无疑问,自动追踪处理这些研究的优势,显著增加了它们的生产力,消除了手动追踪的偏差的变异性.</p><p>It is important to understand that it is usually not sufficient to obtain the basic layout of all labeled neurites.<br>通常是不能充分获取到所有被标记神经的基础布局的,明白它是重要的.<br>In particular, projects aimed at the analyses of synaptic connectivity require accurate knowledge of branching morphology of individual cells (Figure 1).<br>尤其是项目旨在突触连接的分析,需要分裂细胞中分支形态学上扎实的知识.<br>In this study, we use machine learning to evaluate topologically different scenarios of constructing automated traces (Figure 4A) and then determine the correct branching pattern based on previously learned morphological features.<br>在本研究中,我们用机器学习去评估自动重建追踪的不同事态(如图4A),和确定正确的分支模式基于之前所学习的形态学的特点.<br>A machine learning approach to image processing typically requires a large labeled set of examples, and creating such a set can be very time-consuming.<br>偏向图像处理的一个机器学习典型需要一个巨大标记集合例子,和创造非常耗时.<br>Our active learning strategy circumvents this problem by taking advantage of the combinatorial nature of the numbers of branch merging scenarios (Figure 4B).<br>我们主动学习的策略避免了采取大量分支合并情况的自然组合的问题.<br>Another advantage of this strategy is subtractive normalization, Equation (6). Branch merging scenarios are only compared within clusters, normalizing for the variations in local intensity and density of labeled neurites.<br>这个策略其他的优势是减法归一化-等式6.分之合并的方案不仅在集群中比较,还归一化标记的神经的局部强度和密度的变化.</p><p>The results of this study show that the quality of automated traces is strongly dependent on the length density of labeled neurites.<br>这项研究的结果表明，自动化追踪的质量高度依赖于标记的神经突的长度密度。<br>When this density is lower than 0.003 μm−2 the automated tracing algorithm performs on par with trained users (Figure 8D);<br>当该密度低于0.003μm-2时，自动跟踪算法与经训练的用户的表现相同（图8D）;<br>the reliability of automated traces diminishes rapidly with increase in density beyond this point. Hence, proofreading and error-correction may be required for some automated traces.<br>自动追踪的可靠性随着密度的增加而迅速减小,超过该点上。 因此，对于一些自动化追踪可能需要校对和纠错。<br>Proofreading must be done in a computer guided manner, which is particularly important for high-throughput reconstruction projects.<br>校对必须以计算机引导的方式来完成，这对于高通量重建项目尤为重要。<br>The confidence measure described in Equation (10) can be used to convey information about the certainty in the outcome of automated tracing.<br>等式（10）中描述的置信度度量可以用于传达关于自动跟踪的结果的准确度信息。<br>This measure can be calculated for every vertex in the trace and can be used to direct the user’s attention to the most uncertain parts of the trace.<br>该度量可以针对追踪中的每个顶点进行计算，并且可以将用户的注意力引导到追踪的最不确定的部分。<br>Only the lowest confidence mergers will need to be examined by the user, leading to a substantial reduction in proofreading time.<br>只有最低置信度合并将需要由用户检查，校对时间的显着减少。<br>Such low confidence regions can be highlighted automatically and the user would choose from an ordered set of best alternative scenarios (based on decreasing confidence).<br>低置信区域会被自动高亮，用户将从最佳替代方案的有序集合中选择（基于降低的置信度）。</p><p>With the automation of tracing and proofreading it should be possible to map intact, sparsely labeled circuits on the scale of a whole brain, e.g.<br>利用自动化跟踪和校对，应该能够完成映射，例如在整个的大脑的稀疏标记的电路。<br>in the fly or the mouse. Consider a hypothetical experiment of mapping structural connectivity in the mouse brain. The adult mouse brain is roughly 500 mm3 in volume (Ma et al., 2005).<br>在苍蝇或老鼠，考虑到在小鼠大脑中映射结构连通性的假设实验。 成年小鼠脑体积约为500mm 3（Ma et al。，2005）。<br>Subsets of mouse neurons can be labeled in vivo to reveal the layout of their axonal and dendritic arbors.<br>小鼠神经元的子集可以在体内标记，以显示其轴突和树突状突触的布局。<br>The brain can then be divided into 0.5 × 0.5 × 0.1 mm3 optical sections, and imaged in 3D with two-photon or confocal microscopy at 0.5 × 0.5 × 1.0 μm3 spatial resolution.<br>大脑可以分为0.5×0.5×0.1 mm3的光学切片，并在3D中用双光子或共聚焦显微镜以0.5×0.5×1.0μm3的空间分辨率成像。<br>This procedure would result in 20,000 stacks of images, each composed of 1000 × 1000 × 100 voxels, totaling 2 TB of raw imaging data.<br>该过程将产生20,000个图像堆叠，每个图像由1000×1000×100个体素组成，总共2TB的原始成像数据。<br>A dataset of this size would have to be reconstructed on a high-performance computer cluster, and the results could be viewed and proofread on modern-day workstations.<br>这种大小的数据集必须在高性能计算机集群上重建，可在现代工作站上查看和校对结果。<br>Depending on the density of labeling, reconstruction of a single stack may take on the order of 1 core-hour, or 20,000 core-hours for the entire brain.<br>根据标记的密度，单个堆叠的重建可能需要大约1个核心/小时，整个大脑需要20,000个核心/小时。<br>Thus, whole mouse brain mapping is no longer an unfeasible goal.<br>因此，整个小鼠的脑映射不再是一个不可能的目标。</p><p>Brain mapping at a much lower spatial resolution has long been performed with diffusion tensor imaging (DTI).<br>极低空间分辨率的大脑映射解决方案已经用扩散张量成像（DTI）完成。<br>This non-invasive technique measures the diffusion tensor associated with anisotropic movement of water molecules along white matter fiber bundles.<br>这种非侵入式扩散张量测量技术可以与沿着白质纤维束的各向异性运动的水分子相联系。<br>Numerous algorithms have been developed to construct tracts from such information, establishing coarse-grain connectivity between brain regions (for review see Le Bihan, 2003; Hasan et al., 2011; Soares et al., 2013).<br>许多算法已经发展出从相关信息中构造域,如建立脑区之间的粗粒连接 (for review see Le Bihan, 2003; Hasan et al., 2011; Soares et al., 2013).<br>Such algorithms typically use streamline tractography to connect voxels of similar tensor-field orientations into a trace.<br>这种算法通常使用流线纤维成束连接相似张量场方向的体积像素进轨迹中.<br>The reconstruction problem encountered in DTI is somewhat related to the problem of neurite tracing described in this study; however, there is an important difference.<br>在扩散张量成像这个重建问题与在本研究描述的神经突触追踪问题有关,然而这有重要的不同.<br>Due to the relatively low resolution of DTI (typically 1 mm3 per voxel) there is no anatomical basis for trying to detect branching patterns in DTI tracts.<br>由于相对低分辨率的DTI(典型是每体积像素1立方毫米),在DTI追踪中尝试去发现分支模式,这是没有解剖学基础的。<br>Hence, unlike neurite tracing, where topological errors may have a catastrophic effect on the overall connectivity map, the results of DTI tracing are expected to be less sensitive to such errors.<br>因此,不像神经突触的追踪,拓扑错误会灾难性的影响全部连接映射,DTI追踪结果显示对这类错误不敏感.<br>It remains to be seen to what extent brain mapping at single neuron resolution correlates with the connectivity maps established with DTI.<br>尚待分晓的是用DTI单神经分辨率测量相连接的大脑映射能建立到什么程度。</p><h2 id="Conflict-of-Interest-Statement"><a href="#Conflict-of-Interest-Statement" class="headerlink" title="Conflict of Interest Statement"></a>Conflict of Interest Statement</h2><p>利益冲突声明<br>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.<br>作者宣布，该研究是在没有任何商业或财务关系，这可能是一个潜在的利益冲突。</p><h2 id="Acknowledgments"><a href="#Acknowledgments" class="headerlink" title="Acknowledgments"></a>Acknowledgments</h2><p>致谢<br>We thank Vivek Mehta and Paarth Chothani for their significant contributions to the design and development of the NCTracer software, and Soham Mody for testing and debugging the software.<br>谢谢Vivek Mehta 和 Paarth Chothani,他们重大贡献设计和开发的软件 NCTracer ， 和 Soham Mody 为NCTracer软件测试和debugging.<br>Active training, automated tracing, and manual tracing of neurites in this study were performed with NCTracer.<br>在本研究中用NCTracer进行主动训练，自动跟踪和神经突触的手动跟踪。<br>Information on NCTracer can be found at www.neurogeometry.net.<br>NCTracer信息可以在www.neurogeometry.net发现.<br>This work was supported by the NIH grant NS063494.<br>该工作由NIH拨款NS063494支持.</p><p>翻译:刘成德</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Active-learning-of-neuron-morphology-for-accurate-automated-tracing-of-neurites&quot;&gt;&lt;a href=&quot;#Active-learning-of-neuron-morphology-for-
      
    
    </summary>
    
    
      <category term="机器学习" scheme="http://chegde.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>visual studio with markdown</title>
    <link href="http://chegde.github.io/2016/07/15/visual-studio-with-markdown/"/>
    <id>http://chegde.github.io/2016/07/15/visual-studio-with-markdown/</id>
    <published>2016-07-14T16:04:11.000Z</published>
    <updated>2018-01-05T14:27:02.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><ol><li>在vs code中按下ctrl+shift+p,输入install extensions</li><li>寻找 Markdown theme kit 安装,启动即可.</li><li>可以使用vs code命令呼出markdown: open preview或使用ctrl+shift+v</li></ol><h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档:"></a>参考文档:</h2><p><a href="https://code.visualstudio.com/docs/languages/markdown" target="_blank" rel="noopener">https://code.visualstudio.com/docs/languages/markdown</a></p><p>该参考文档主要说明了以下功能操作步骤</p><ol><li>markdown插件</li><li>使用自己的样式</li><li>增加自义定代码片段</li><li>编译markdown成为html</li><li>自动编译markdown</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;安装&quot;&gt;&lt;a href=&quot;#安装&quot; class=&quot;headerlink&quot; title=&quot;安装&quot;&gt;&lt;/a&gt;安装&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;在vs code中按下ctrl+shift+p,输入install extensions&lt;/li&gt;
&lt;li&gt;寻找 Markdow
      
    
    </summary>
    
    
      <category term="编辑器" scheme="http://chegde.github.io/tags/%E7%BC%96%E8%BE%91%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>hexo</title>
    <link href="http://chegde.github.io/2016/07/14/hexo/"/>
    <id>http://chegde.github.io/2016/07/14/hexo/</id>
    <published>2016-07-14T14:41:32.000Z</published>
    <updated>2018-01-05T14:27:02.000Z</updated>
    
    <content type="html"><![CDATA[<p>如何利用github page搭建博客基于hexo<br>hexo是nodejs的博客框架,使用markdown</p><h3 id="资源"><a href="#资源" class="headerlink" title="资源"></a>资源</h3><pre><code>https://hexo.io/zh-cn/docs/</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;如何利用github page搭建博客基于hexo&lt;br&gt;hexo是nodejs的博客框架,使用markdown&lt;/p&gt;
&lt;h3 id=&quot;资源&quot;&gt;&lt;a href=&quot;#资源&quot; class=&quot;headerlink&quot; title=&quot;资源&quot;&gt;&lt;/a&gt;资源&lt;/h3&gt;&lt;pre&gt;&lt;cod
      
    
    </summary>
    
    
      <category term="博客" scheme="http://chegde.github.io/tags/%E5%8D%9A%E5%AE%A2/"/>
    
  </entry>
  
  <entry>
    <title>leetcode</title>
    <link href="http://chegde.github.io/2016/07/02/leetcode/"/>
    <id>http://chegde.github.io/2016/07/02/leetcode/</id>
    <published>2016-07-02T15:16:11.000Z</published>
    <updated>2018-01-05T14:27:02.000Z</updated>
    
    <content type="html"><![CDATA[<p>二进制问题</p><h3 id="338-Counting-Bits"><a href="#338-Counting-Bits" class="headerlink" title="338. Counting Bits"></a>338. Counting Bits</h3><p><a href="https://leetcode.com/problems/counting-bits/" target="_blank" rel="noopener">https://leetcode.com/problems/counting-bits/</a></p><h5 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h5><p>求0到n的二进制表示的1的数量</p><h5 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h5><p>二进制+进位处理+遍历统计1位数目(最低效)</p><h5 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    vector&lt;int&gt; countBits(int num) &#123;</span><br><span class="line">        vector&lt;int&gt; ret(num+1, 0);</span><br><span class="line">        for (int i = 1; i &lt;= num; ++i)</span><br><span class="line">            ret[i] = ret[i&amp;(i-1)] + 1;</span><br><span class="line">        return ret;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>重点在于 ret[i] = ret[i&amp;(i-1)] + 1</p><ul><li>应该寻找序列规律</li><li>i&amp;(i-1)的本质是2的次方所表示的范围</li><li>思考i&amp;(i-1)在算术上是什么作用</li></ul><h3 id="191-Number-of-1-Bits"><a href="#191-Number-of-1-Bits" class="headerlink" title="191. Number of 1 Bits"></a>191. Number of 1 Bits</h3><p><a href="https://leetcode.com/problems/number-of-1-bits/" target="_blank" rel="noopener">https://leetcode.com/problems/number-of-1-bits/</a></p><h5 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h5><p>求一个数的二进制表示法中的1的数量</p><h5 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">int hammingWeight(uint32_t n) &#123;</span><br><span class="line">    return n == 0 ? 0 : 1 + hammingWeight(n &amp; (n - 1));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>思考i&amp;(i-1)到底做了什么<h5 id="思路1"><a href="#思路1" class="headerlink" title="思路1"></a>思路1</h5>使用&amp;运算,(i&amp;(i-1))的递推+1可得到二进制中1的数量<h5 id="思路2"><a href="#思路2" class="headerlink" title="思路2"></a>思路2</h5>逻辑与运算1，像右移位并统计。</li></ul><p>组合博奕</p><h3 id="292-Nim-Game"><a href="#292-Nim-Game" class="headerlink" title="292. Nim Game"></a>292. Nim Game</h3><p><a href="https://leetcode.com/problems/nim-game/" target="_blank" rel="noopener">https://leetcode.com/problems/nim-game/</a></p><h5 id="问题-2"><a href="#问题-2" class="headerlink" title="问题"></a>问题</h5><p>一堆石头,你和对手都可以拿走1-3个石头,最后拿光的那个人赢,我先手,求是否能赢</p><h5 id="思路-1"><a href="#思路-1" class="headerlink" title="思路"></a>思路</h5><p>保持P状态就可赢,P状态指的是最小+最大可减数目=p状态<br>是否能进入p状态,n % 4 != 0 即可必胜</p><h5 id="代码-2"><a href="#代码-2" class="headerlink" title="代码"></a>代码</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    bool canWinNim(int n) &#123;</span><br><span class="line">        return n&amp;3;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="136-Single-Number"><a href="#136-Single-Number" class="headerlink" title="136. Single Number"></a>136. Single Number</h3><p><a href="https://leetcode.com/problems/single-number/" target="_blank" rel="noopener">https://leetcode.com/problems/single-number/</a></p><h5 id="问题-3"><a href="#问题-3" class="headerlink" title="问题"></a>问题</h5><p>给一数组,每个数都出现两次,除了一个,找出那一个数.</p><h5 id="思路-2"><a href="#思路-2" class="headerlink" title="思路"></a>思路</h5><p>异或算符的值为真仅当两个运算元中恰有一个的值为真，而另外一个的值为非真。<br>Xor运算 == 俩二进制不同为真</p><h5 id="代码-3"><a href="#代码-3" class="headerlink" title="代码"></a>代码</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">int singleNumber(vector&lt;int&gt;&amp; nums) &#123;</span><br><span class="line">int single = 0;</span><br><span class="line">for (unsigned int i = 0; i &lt; nums.size(); i++) &#123;</span><br><span class="line">single ^= nums[i];</span><br><span class="line">&#125;</span><br><span class="line">return single;</span><br><span class="line">&#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="258-Add-Digits"><a href="#258-Add-Digits" class="headerlink" title="258. Add Digits"></a>258. Add Digits</h3><p><a href="https://leetcode.com/problems/add-digits/" target="_blank" rel="noopener">https://leetcode.com/problems/add-digits/</a></p><h5 id="问题-4"><a href="#问题-4" class="headerlink" title="问题"></a>问题</h5><p>给定一个非负数,对每位数进行相加,直到结果为一位数</p><h5 id="思路-3"><a href="#思路-3" class="headerlink" title="思路"></a>思路</h5><p>寻找规律,发现结果为对输入数进行9的求余<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    int addDigits(int num) &#123;</span><br><span class="line">if (num &lt; 9) return num;</span><br><span class="line">return (num %= 9) ? num : 9;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><h3 id="104-Maximum-Depth-of-Binary-Tree"><a href="#104-Maximum-Depth-of-Binary-Tree" class="headerlink" title="104. Maximum Depth of Binary Tree"></a>104. Maximum Depth of Binary Tree</h3><h5 id="问题-5"><a href="#问题-5" class="headerlink" title="问题"></a>问题</h5><p>求二叉树的最大深度</p><h5 id="代码-4"><a href="#代码-4" class="headerlink" title="代码"></a>代码</h5><p>Depth-first-search<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">int maxDepth(TreeNode* root) &#123;</span><br><span class="line">return root == NULL ? 0 : max(maxDepth(root-&gt;left), maxDepth(root-&gt;right))+1;</span><br><span class="line">&#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><p>Breadth-first-search<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">int maxDepth(TreeNode *root)</span><br><span class="line">&#123;</span><br><span class="line">    if(root == NULL)</span><br><span class="line">        return 0;</span><br><span class="line">    </span><br><span class="line">    int res = 0;</span><br><span class="line">    queue&lt;TreeNode *&gt; q;</span><br><span class="line">    q.push(root);</span><br><span class="line">    while(!q.empty())</span><br><span class="line">    &#123;</span><br><span class="line">        ++ res;</span><br><span class="line">        for(int i = 0, n = q.size(); i &lt; n; ++ i)</span><br><span class="line">        &#123;</span><br><span class="line">            TreeNode *p = q.front();</span><br><span class="line">            q.pop();</span><br><span class="line">            </span><br><span class="line">            if(p -&gt; left != NULL)</span><br><span class="line">                q.push(p -&gt; left);</span><br><span class="line">            if(p -&gt; right != NULL)</span><br><span class="line">                q.push(p -&gt; right);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    return res;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;二进制问题&lt;/p&gt;
&lt;h3 id=&quot;338-Counting-Bits&quot;&gt;&lt;a href=&quot;#338-Counting-Bits&quot; class=&quot;headerlink&quot; title=&quot;338. Counting Bits&quot;&gt;&lt;/a&gt;338. Counting Bits&lt;/h
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>immunology 免疫学</title>
    <link href="http://chegde.github.io/2016/06/27/immunology/"/>
    <id>http://chegde.github.io/2016/06/27/immunology/</id>
    <published>2016-06-27T07:16:00.000Z</published>
    <updated>2018-01-05T14:27:02.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="免疫器官"><a href="#免疫器官" class="headerlink" title="免疫器官"></a>免疫器官</h1><hr><h3 id="造血干细胞的分化。"><a href="#造血干细胞的分化。" class="headerlink" title="造血干细胞的分化。"></a>造血干细胞的分化。</h3><p>造血干细胞（hematopietic stem cells）可分化为各种免疫细胞（不包括成熟T细胞）</p><h3 id="中枢免疫器官的组成和功能。"><a href="#中枢免疫器官的组成和功能。" class="headerlink" title="中枢免疫器官的组成和功能。"></a>中枢免疫器官的组成和功能。</h3><p>骨髓（bone marrow）在出生前后，主要承担造血功能，是各类免疫细胞以及T细胞的前体细胞的发生场所</p><p>胸腺是T细胞分化成熟的场所。在胸腺分化成熟的T细胞主要是αβT细胞，此外尚有γδT细胞和NKT细胞。</p><h3 id="T细胞和B细胞的发育。"><a href="#T细胞和B细胞的发育。" class="headerlink" title="T细胞和B细胞的发育。"></a>T细胞和B细胞的发育。</h3><pre><code>T细胞简单发育过程 来自骨髓的淋巴样干细胞通过胸腺被膜下区进入皮质区 （成为胸腺细胞），向皮髓质交界处移行，再向髓质区移行，在移行过程中逐渐成熟。在移行中胸腺细胞表面分子的变化：双阴性(CD4- CD8-）胸腺（T）细胞（存在于胸腺被膜下区和皮质边缘区）双阳性（CD4+ CD8+）胸腺细胞（主要存在于皮质深区）单阳性(CD4+或CD8+ )TCRαβ T细胞（存在于皮髓质交界处及髓质区）进入外周免疫器官或血液B细胞淋巴样前体细胞从邻近骨内表面的骨髓膜下区向骨髓腔中心移行，并在移行中逐渐发育成熟。  淋巴样前体细胞 祖B细胞（pro-B ）前B细胞(pre-B) 未成熟B细胞 成熟B细胞(定居在外周免疫器官)</code></pre><h3 id="外周免疫器官的组成和功能。"><a href="#外周免疫器官的组成和功能。" class="headerlink" title="外周免疫器官的组成和功能。"></a>外周免疫器官的组成和功能。</h3><pre><code>淋巴结功能（1）滤过作用。巨噬细胞（2）t细胞和b细胞定居的场所。（3）免疫应答发生的部位。（4）参与淋巴细胞再循环。  来自血液的淋巴细胞穿过HEV壁进入淋巴实质部位，在随淋巴液通过输出淋巴管进入胸导管或右淋巴管，回到血液循环。脾功能（1）有滤过作用，可清除血液中的病原体、衰老的红细胞及废物，净化血液。（2）免疫细胞定居的场所。（3）淋巴细胞受抗原刺激并产生免疫应答的主要部位。（4）能合成某些生物活性物质，如补体，干扰素等。</code></pre><h1 id="免疫球蛋白"><a href="#免疫球蛋白" class="headerlink" title="免疫球蛋白"></a>免疫球蛋白</h1><hr><h3 id="阐述免疫球蛋白的基本结构及各个功能区的意义"><a href="#阐述免疫球蛋白的基本结构及各个功能区的意义" class="headerlink" title="阐述免疫球蛋白的基本结构及各个功能区的意义"></a>阐述免疫球蛋白的基本结构及各个功能区的意义</h3><p>具有抗体活性或化学结构与抗体分子相似的球蛋白。(antibody Ab, BCR,其他分子)</p><p>由四条肽链组成，即由两条相同的分子量较小的肽链，称为轻链，另外两条相同的分子量较大的肽链，称为重链组成，轻链与重链是二硫键连接形成一个四肽链分子，称为Ig分子单体</p><p><img src="http://i.imgur.com/ECYYi62.png" alt=""></p><p>功能区：是不连续，紧密折叠的区域，由重链和轻链经链内二硫键连接而成的球状结构。</p><ol><li>VL和VH是抗原结合的部位（FV区）。</li><li>CL和CH上具有同种异型的遗传标记。</li><li>IgG的CH2和IgM的CH3具有补体固有成分C1q的结合点，参与激活补体系统。</li><li>CH3/CH4具有结合包括单核细胞、巨噬细胞、粒细胞、B细胞、NK细胞等细胞的Fc段受体的功能。</li><li>IgG的CH2+CH3 具有介导IgG通过胎盘的特性。</li></ol><h3 id="阐述免疫球蛋白的水解片断"><a href="#阐述免疫球蛋白的水解片断" class="headerlink" title="阐述免疫球蛋白的水解片断"></a>阐述免疫球蛋白的水解片断</h3><p><img src="http://i.imgur.com/RHQuwSC.jpg" alt=""></p><h3 id="简述五大类免疫球蛋白具有不同的理化特性和生物学功能"><a href="#简述五大类免疫球蛋白具有不同的理化特性和生物学功能" class="headerlink" title="简述五大类免疫球蛋白具有不同的理化特性和生物学功能"></a>简述五大类免疫球蛋白具有不同的理化特性和生物学功能</h3><p>IgG</p><ul><li>再次免疫应答产生的主要抗体</li><li>IgG可以穿过胎盘屏障</li><li>IgG(1,2,3)的CH2能通过经典途径活化补体</li><li>单体IgM以膜结合型（mIgM）表达于B细胞表面，构成BCR</li></ul><p>IgM</p><ul><li>分泌型IgM为五聚体，是分子量最大的Ig</li><li>最早合成和分泌</li><li>二聚体</li></ul><p>IgA</p><ul><li>外分泌液中的主要抗体</li><li>通过与相应病原微生物（细菌、病毒等）结合，阻止病原体黏附到细胞表面</li><li>B细胞分化发育成熟的标志</li></ul><p>IgD</p><ul><li>膜结合型IgD（mIgD）构成BCR</li><li>含量最少</li></ul><p>IgE</p><ul><li>引起I型超敏反应</li><li>抗寄生虫免疫<h3 id="同种型、同种异型和独特型的概念"><a href="#同种型、同种异型和独特型的概念" class="headerlink" title="同种型、同种异型和独特型的概念"></a>同种型、同种异型和独特型的概念</h3></li></ul><p><img src="http://i.imgur.com/HXu6SeZ.png" alt=""></p><h3 id="单克隆抗体"><a href="#单克隆抗体" class="headerlink" title="单克隆抗体"></a>单克隆抗体</h3><p>由单一克隆B细胞杂交瘤产生的、只识别抗原分子某一特定抗原决定簇的、具有高度特异性的抗体。每种单克隆抗体其类、亚类、型及亲和力完全相同，具有高度均一性。</p><p><img src="http://i.imgur.com/42cweYu.jpg" alt=""></p><h1 id="补体"><a href="#补体" class="headerlink" title="补体"></a>补体</h1><hr><h3 id="补体系统的概念及其组成。"><a href="#补体系统的概念及其组成。" class="headerlink" title="补体系统的概念及其组成。"></a>补体系统的概念及其组成。</h3><p>由存在于人和脊椎动物血清及组织液中的一组经活化后具有酶样活性的蛋白质，以及其调节蛋白和相关膜蛋白（受体）共同组成的系统(The Complement system)。</p><p>补体的固有成分：补体激活级联反应的补体成分</p><h3 id="补体三条激活途径的异同。"><a href="#补体三条激活途径的异同。" class="headerlink" title="补体三条激活途径的异同。"></a>补体三条激活途径的异同。</h3><p><img src="http://i.imgur.com/LOAif7D.png" alt=""></p><p><img src="http://i.imgur.com/eOWOqEC.png" alt=""></p><h3 id="补体激活的调节机制。"><a href="#补体激活的调节机制。" class="headerlink" title="补体激活的调节机制。"></a>补体激活的调节机制。</h3><h3 id="补体系统的生物学作用。"><a href="#补体系统的生物学作用。" class="headerlink" title="补体系统的生物学作用。"></a>补体系统的生物学作用。</h3><ul><li>MAC介导的细胞裂解作用 补体系统活化 → 膜攻击复合物 →溶解靶细胞</li><li>补体活化片段介导的生物学作用 调理作用 免疫复合物清除作用 </li><li>清除凋亡细胞</li><li>炎症介质作用</li><li>免疫调节作用</li></ul><h3 id="C3的生物学功能。"><a href="#C3的生物学功能。" class="headerlink" title="C3的生物学功能。"></a>C3的生物学功能。</h3>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;免疫器官&quot;&gt;&lt;a href=&quot;#免疫器官&quot; class=&quot;headerlink&quot; title=&quot;免疫器官&quot;&gt;&lt;/a&gt;免疫器官&lt;/h1&gt;&lt;hr&gt;
&lt;h3 id=&quot;造血干细胞的分化。&quot;&gt;&lt;a href=&quot;#造血干细胞的分化。&quot; class=&quot;headerlink&quot; t
      
    
    </summary>
    
    
      <category term="海洋科学" scheme="http://chegde.github.io/tags/%E6%B5%B7%E6%B4%8B%E7%A7%91%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>Cyclostomata 圆口类</title>
    <link href="http://chegde.github.io/2016/06/27/Cyclostomata/"/>
    <id>http://chegde.github.io/2016/06/27/Cyclostomata/</id>
    <published>2016-06-27T07:13:52.000Z</published>
    <updated>2018-01-05T14:27:02.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="圆口类-Cyclostomata"><a href="#圆口类-Cyclostomata" class="headerlink" title="圆口类 Cyclostomata"></a>圆口类 Cyclostomata</h1><h2 id="无颌总纲（Superclass-Agnatha）"><a href="#无颌总纲（Superclass-Agnatha）" class="headerlink" title="无颌总纲（Superclass Agnatha）"></a>无颌总纲（Superclass Agnatha）</h2><h3 id="囊鳃类-Marsipobranchii"><a href="#囊鳃类-Marsipobranchii" class="headerlink" title="囊鳃类 (Marsipobranchii)"></a>囊鳃类 (Marsipobranchii)</h3><h4 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h4><ol><li>无上下颌。</li><li>脊索终生存在，没有脊椎。</li><li>没有偶鳍，只有奇鳍，无肩带和腰带。</li><li>呼吸器官为鳃囊。</li></ol><p><img src="http://i.imgur.com/w50Vb3Q.jpg" alt=""></p><h3 id="头甲鱼纲（Class-Cephalaspidomorphi）"><a href="#头甲鱼纲（Class-Cephalaspidomorphi）" class="headerlink" title="头甲鱼纲（Class Cephalaspidomorphi）"></a>头甲鱼纲（Class Cephalaspidomorphi）</h3><h4 id="七鳃鳗目-Petromyzoniformes"><a href="#七鳃鳗目-Petromyzoniformes" class="headerlink" title="七鳃鳗目  Petromyzoniformes"></a>七鳃鳗目  Petromyzoniformes</h4><ul><li>眼在成体时发达；口呈漏斗状吸盘。鳃囊7对，分别开口于体外，故称七鳃鳗。</li><li>半寄生性的种类。完全生活于淡水或溯河产卵。</li><li>我国仅产1科l属3种。均分布于东北地区。</li></ul><p><img src="http://i.imgur.com/v5zOxiK.jpg" alt="日本七鳃鳗：体长可达625mm，体重可达237g以上，溯河产卵型鱼类。"></p><h3 id="盲鳗纲-Class-Myxini"><a href="#盲鳗纲-Class-Myxini" class="headerlink" title="盲鳗纲 Class Myxini"></a>盲鳗纲 Class Myxini</h3><h4 id="盲鳗目-Myxiniformes"><a href="#盲鳗目-Myxiniformes" class="headerlink" title="盲鳗目    Myxiniformes"></a>盲鳗目    Myxiniformes</h4><ul><li>眼埋于皮下，无口漏斗，口呈孔状。</li><li>皮肤粘液腺显著发达。</li><li>腐食性，多摄食垂死或死亡的无脊椎动物或鱼类。</li><li>所有的盲鳗均属海产种类，栖息于温带或亚热带水域中。主要以鱼类为食。</li><li>我国现知仅产盲鳗科Myxinidae粘盲鳗亚科2属9种。如蒲氏粘盲鳗、紫粘盲鳗。 </li></ul><p><img src="http://i.imgur.com/ogF6rcI.jpg" alt=""></p><h4 id="鱼类的演化"><a href="#鱼类的演化" class="headerlink" title="鱼类的演化"></a>鱼类的演化</h4><p><img src="http://i.imgur.com/0Z2AqV4.png" alt=""></p><p><img src="http://i.imgur.com/QMqRGVe.png" alt=""></p><h2 id="有颌总纲（Superclass-Gnathostomata"><a href="#有颌总纲（Superclass-Gnathostomata" class="headerlink" title="有颌总纲（Superclass Gnathostomata)"></a>有颌总纲（Superclass Gnathostomata)</h2><ul><li>盾皮鱼纲（Class Placodermi）（化石）</li><li>软骨鱼纲 （Class Chondrichthyes)</li><li>棘鱼纲（Class Acanthodii）（化石）</li><li>肉鳍鱼纲 （Class Sarcopterygii）</li><li>辐鳍鱼纲 （Class Actinopterygii）</li></ul><h3 id="软骨鱼纲-（Class-Chondrichthyes"><a href="#软骨鱼纲-（Class-Chondrichthyes" class="headerlink" title="软骨鱼纲 （Class Chondrichthyes)"></a>软骨鱼纲 （Class Chondrichthyes)</h3><ul><li>内骨骼全为软骨。外骨骼为盾鳞或光滑无鳞，鳍条为角质鳍条。</li><li>头部每侧具有5—7个鳃裂，各自开口于体外；或具4个鳃裂，外被一膜状鳃盖，其后具一总鳃孔。</li><li>雄性具有鳍脚，体内受精。</li><li>肠短，具螺旋瓣；无鳔。</li><li>歪型尾。</li><li>卵大而少，卵生、胎生或卵胎生。</li></ul><p>亚纲特征：鳃孔5—7对，分别开口于体外；上颌不与头颅愈合；雄性无腹前鳍脚和额上鳍脚。 </p><h4 id="板鳃亚纲-Subclass-Elasmobranchii"><a href="#板鳃亚纲-Subclass-Elasmobranchii" class="headerlink" title="板鳃亚纲 Subclass Elasmobranchii"></a>板鳃亚纲 Subclass Elasmobranchii</h4><h5 id="侧孔总目-Pleurotremata（鲨形总目-Selachomorpha）：340种"><a href="#侧孔总目-Pleurotremata（鲨形总目-Selachomorpha）：340种" class="headerlink" title="侧孔总目 Pleurotremata（鲨形总目 Selachomorpha）：340种"></a>侧孔总目 Pleurotremata（鲨形总目 Selachomorpha）：340种</h5><blockquote><p>鳃裂位于头部两侧，体常呈纺锤形，胸鳍前缘游离，与体侧和头侧不愈合；</p></blockquote><ul><li>皱鳃鲨目：鳃间隔延长而褶皱，相互覆盖；口端位；  </li><li>六鳃鲨目：6～7个鳃裂，背鳍1个。</li><li>锯鲨目：吻锯状</li><li>扁鲨目：体扁平</li><li>角鲨目：无臀鳍</li><li>虎鲨目：背鳍前具硬棘、有臀鳍，具口鼻沟</li><li>真鲨目：背鳍前无硬棘、眼有瞬膜或瞬褶、有臀鳍</li><li>须鲨目：背鳍前无硬棘、眼无瞬膜或瞬褶、具鼻口沟或鼻孔开口于体内、有臀鳍</li><li>鼠鲨目|鲭鲨目(Lamniformes)：背鳍前无硬棘、眼无瞬膜或瞬褶、无鼻口沟、鼻孔不开口于体内、体似鲭科鱼类、有臀鳍。</li></ul><p><img src="http://i.imgur.com/Tbqkbmg.jpg" alt=""></p><h5 id="六鳃鲨目"><a href="#六鳃鲨目" class="headerlink" title="六鳃鲨目"></a>六鳃鲨目</h5><blockquote><p>特征：鳃孔6—7对；背鳍1个，无硬棘，有臀鳍；有喷水孔。</p></blockquote><p>皱鳃鲨</p><p><img src="http://i.imgur.com/kggPOiR.png" alt=""></p><p>枝齿鲨 灭绝 体长达12-14米</p><p>扁头哈那鲨：鳃孔7个，体长可达3m，重数百斤。皮可制革，肉可使用，肝可制鱼肝油。但是它在六鳃鲨目分类下。</p><p><img src="http://i.imgur.com/yMEPHwJ.jpg" alt=""></p><h5 id="虎鲨目"><a href="#虎鲨目" class="headerlink" title="虎鲨目"></a>虎鲨目</h5><blockquote><p>特征：背鳍2个，各具1硬棘，具臀鳍，鳃孔5个。无吻软骨。具口鼻沟。<br>我国产1科1属2种：宽纹虎鲨和狭纹虎鲨。</p></blockquote><p>狭纹虎鲨</p><p><img src="http://i.imgur.com/xlS6lMa.jpg" alt=""></p><h5 id="鼠鲨目-鲭鲨目-Lamniformes"><a href="#鼠鲨目-鲭鲨目-Lamniformes" class="headerlink" title="鼠鲨目|鲭鲨目(Lamniformes)"></a>鼠鲨目|鲭鲨目(Lamniformes)</h5><blockquote><p>背鳍2个，无硬棘，具臀鳍。鳃孔5个。无瞬膜或瞬褶。口伸至眼后。<br>全世界共有4科10属约16种。我国有5科6属11种。</p></blockquote><ul><li>锥齿鲨科</li><li>鲭鲨科（鼠鲨科）</li><li>姥鲨科</li><li>长尾鲨科</li></ul><h6 id="锥齿鲨科Carchariidae"><a href="#锥齿鲨科Carchariidae" class="headerlink" title="锥齿鲨科Carchariidae"></a>锥齿鲨科Carchariidae</h6><p>特征：尾柄无侧突，上方具一凹洼，齿大，锥状。本科我国现知产1属2种：欧氏锥齿鲨和沙锥齿鲨。均属底层或近底层凶猛鱼类，体长可达2m以上。</p><p><img src="http://i.imgur.com/of6iOmG.jpg" alt=""></p><h6 id="鲭鲨科Isuridae（鼠鲨科Lamnidae）"><a href="#鲭鲨科Isuridae（鼠鲨科Lamnidae）" class="headerlink" title="鲭鲨科Isuridae（鼠鲨科Lamnidae）"></a>鲭鲨科Isuridae（鼠鲨科Lamnidae）</h6><p>背鳍2个，第二背鳍和臀鳍很小。尾柄较细长，具侧突。口大，齿大而锐利。眼无瞬膜。无鳃耙。<br>为一群性较凶猛而善游泳的鱼类。我国产2种：<br>灰鲭鲨：性凶猛，体长达4m以上，我国分布于东海及南海。<br>噬人鲨：体长可达7m左右，广泛分布于各热带或温带海区。</p><p><img src="http://i.imgur.com/y3oLKpX.jpg" alt=""></p><h6 id="姥鲨科-Cetorhinidae"><a href="#姥鲨科-Cetorhinidae" class="headerlink" title="姥鲨科 Cetorhinidae"></a>姥鲨科 Cetorhinidae</h6><p>鳃弓密具细长角质鳃耙，成为过滤器，鳃裂很大。<br>仅1属1种：姥鲨。</p><p><img src="http://i.imgur.com/eG2fhMs.jpg" alt=""></p><h6 id="长尾鲨科-Alopiidae"><a href="#长尾鲨科-Alopiidae" class="headerlink" title="长尾鲨科 Alopiidae"></a>长尾鲨科 Alopiidae</h6><p>尾很长，大于全长之半，呈镰刀形。<br>我国只产长尾鲨属l属3种。<br>弧形长尾鲨：成鱼长达6m以上。我国分布于黄海、东海、南海。较常见。</p><p><img src="http://i.imgur.com/jMX4TBM.jpg" alt=""></p><h5 id="须鲨目-Orectolobiformes"><a href="#须鲨目-Orectolobiformes" class="headerlink" title="须鲨目  Orectolobiformes"></a>须鲨目  Orectolobiformes</h5><p>特征：鼻孔具鼻口沟或鼻孔开口于口内，前鼻瓣常具一鼻须或喉部具一对皮须。无瞬膜，背鳍2个。卵胎生或胎生。<br>我国有3科8属12种。</p><ul><li>须鲨科</li><li>橙黄鲨科</li><li>鲸鲨科</li></ul><h6 id="须鲨科-Orectolobidae"><a href="#须鲨科-Orectolobidae" class="headerlink" title="须鲨科 Orectolobidae"></a>须鲨科 Orectolobidae</h6><p>具口鼻沟。具鼻须。<br>本科我国产有5属，常见种类：<br>日本须鲨：头侧具一系列皮瓣。为暖温性中小型鲨类，体长1m左右。大的可达2m。卵胎生。我国产于东海和南海。</p><p><img src="http://i.imgur.com/H6xSgYF.jpg" alt=""></p><h6 id="橙黄鲨科-Cirrhoscylliidae"><a href="#橙黄鲨科-Cirrhoscylliidae" class="headerlink" title="橙黄鲨科 Cirrhoscylliidae"></a>橙黄鲨科 Cirrhoscylliidae</h6><p>喉部具1对皮须。无鼻须，喷水孔细小。为小型鲨类，最大长度91cm。我国只产橙黄鲨1种。分布于南海。</p><p><img src="http://i.imgur.com/VJahNXH.jpg" alt=""></p><h6 id="鲸鲨科-Rhincodontidae"><a href="#鲸鲨科-Rhincodontidae" class="headerlink" title="鲸鲨科 Rhincodontidae"></a>鲸鲨科 Rhincodontidae</h6><p>体庞大，每侧具2条显著突起的皮嵴。口大，鳃裂宽大，鳃弓具角质鳃耙，鳃耙成海绵状的过滤器。</p><p>鲸鲨：大洋性大型鲨类，最大体长达20m，重5t。为鱼类中的冠军。广泛分布于温热带海区，我国沿海偶有捕获。</p><p><img src="http://i.imgur.com/WIj2Yiz.jpg" alt=""></p><h5 id="真鲨目-Carcharhiniformes"><a href="#真鲨目-Carcharhiniformes" class="headerlink" title="真鲨目 Carcharhiniformes"></a>真鲨目 Carcharhiniformes</h5><p>特征：眼有瞬膜或瞬褶；背鳍2个，无硬棘；具臀鳍；鳃裂5个。<br>本目我国产5科60多种，是我国软骨鱼类中种类最多的一个类群。</p><ol><li>猫鲨科</li><li>皱唇鲨科</li><li>拟皱唇鲨科</li><li>真鲨科</li><li>双髻鲨科</li></ol><h6 id="猫鲨科"><a href="#猫鲨科" class="headerlink" title="猫鲨科"></a>猫鲨科</h6><p>齿细小作带状或铺石状排列，多行使用；上眼睑上部分化为瞬褶，能上闭。喷水孔显著。第一背鳍位于腹鳍上方或腹鳍之后。<br>本科我国有7属，常见种：<br>阴影绒毛鲨：体上具有斑点和暗色横纹。分布于南海及东海南部。<br>梅花鲨：体具<br>黑色圆斑，似梅花<br>状排列。见于南海<br>和东海南部。</p><h6 id="皱唇鲨科"><a href="#皱唇鲨科" class="headerlink" title="皱唇鲨科"></a>皱唇鲨科</h6><p>喷水孔显著。齿小而多，三齿头或多齿头型。第一背鳍位于胸鳍与腹鳍之间的上方或较接近腹鳍。<br>本科我国产有4属，常见种类：<br>皱唇鲨Triakis scyllium：<br>白斑星鲨 Mustelus manazo：</p><p><img src="http://i.imgur.com/NVnugGv.jpg" alt=""></p><h6 id="真鲨科"><a href="#真鲨科" class="headerlink" title="真鲨科"></a>真鲨科</h6><p>瞬膜发达，喷水孔细小或消失。齿1—3行使用。<br>我国产12属30余种，是现代鲨类中种数最多的一类。其中斜齿鲨属 Scoliodon和真鲨属Carcharhinus最常见。<br>黑印真鲨 Carcharhinus menisorrah<br>尖头斜齿鲨<br>沙拉真鲨</p><p><img src="http://i.imgur.com/ZV1QIJL.jpg" alt=""></p><h6 id="双髻鲨科"><a href="#双髻鲨科" class="headerlink" title="双髻鲨科"></a>双髻鲨科</h6><p>具有“T”字形头部，头的额区向左右突出。眼圆形，位于突出的两端。<br>本科仅有双髻鲨属l属，我国产 5种。<br>锤头双髻鲨 Sphyrna lewini：较为常见，为外海性大型凶猛鱼类，体长一般在lm左右，大者有长达3m，重110 kg的，我国沿海都有产，肉可食、鳍可制鱼翅。</p><p><img src="http://i.imgur.com/ZdBfNM0.jpg" alt=""></p><h5 id="角鲨目-Squaliformes"><a href="#角鲨目-Squaliformes" class="headerlink" title="角鲨目 Squaliformes"></a>角鲨目 Squaliformes</h5><p>特征：背鳍2个，无臀鳍。<br>全世界有3科22属约90种。我国有1科6属10种。</p><p><img src="http://i.imgur.com/KA3Rb5e.jpg" alt=""></p><h5 id="锯鲨目-Pristiophoriformes"><a href="#锯鲨目-Pristiophoriformes" class="headerlink" title="锯鲨目 Pristiophoriformes"></a>锯鲨目 Pristiophoriformes</h5><p>特征：吻很长，剑状突出。眼具瞬褶。喷水孔大。<br>我国仅产一种：<br>日本锯鲨：体长达4m，肉质优良。</p><p><img src="http://i.imgur.com/P97U8St.jpg" alt=""></p><h5 id="扁鲨目-squatiniformes"><a href="#扁鲨目-squatiniformes" class="headerlink" title="扁鲨目  squatiniformes"></a>扁鲨目  squatiniformes</h5><p>特征：体扁平，吻宽。胸鳍扩大，前缘游离。<br>只有扁鲨科扁鲨属12种。我国产2种：</p><p><img src="http://i.imgur.com/ovCRa0J.jpg" alt=""></p><h5 id="下孔总目-Hypotremata（鳐形总目-Batomorphp）：430种"><a href="#下孔总目-Hypotremata（鳐形总目-Batomorphp）：430种" class="headerlink" title="下孔总目 Hypotremata（鳐形总目 Batomorphp）：430种"></a>下孔总目 Hypotremata（鳐形总目 Batomorphp）：430种</h5><p>鳃裂位于头部腹面，体平扁而宽，常呈菱形或盘形，胸鳍前缘与体侧或头侧愈合。</p><h5 id="全头亚纲-Subclass-Holocephali"><a href="#全头亚纲-Subclass-Holocephali" class="headerlink" title="全头亚纲 Subclass Holocephali"></a>全头亚纲 Subclass Holocephali</h5><ul><li>银鲛目Chimaeriformes：30种</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;圆口类-Cyclostomata&quot;&gt;&lt;a href=&quot;#圆口类-Cyclostomata&quot; class=&quot;headerlink&quot; title=&quot;圆口类 Cyclostomata&quot;&gt;&lt;/a&gt;圆口类 Cyclostomata&lt;/h1&gt;&lt;h2 id=&quot;无颌总纲（Supe
      
    
    </summary>
    
    
      <category term="海洋科学" scheme="http://chegde.github.io/tags/%E6%B5%B7%E6%B4%8B%E7%A7%91%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>ichthyography 鱼类学</title>
    <link href="http://chegde.github.io/2016/06/27/ichthyography/"/>
    <id>http://chegde.github.io/2016/06/27/ichthyography/</id>
    <published>2016-06-27T07:12:57.000Z</published>
    <updated>2018-01-05T14:27:02.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="鱼类学"><a href="#鱼类学" class="headerlink" title="鱼类学"></a>鱼类学</h1><h2 id="一、绪论"><a href="#一、绪论" class="headerlink" title="一、绪论"></a>一、绪论</h2><h3 id="1-鱼类学主要研究哪些内容？有哪些分支学科？"><a href="#1-鱼类学主要研究哪些内容？有哪些分支学科？" class="headerlink" title="1.    鱼类学主要研究哪些内容？有哪些分支学科？"></a>1.    鱼类学主要研究哪些内容？有哪些分支学科？</h3><p>鱼类学(Ichthyology)研究鱼类的外部形态、内部构造、生活习性、种类区分和分布特点等方面的问题。<br>鱼类学的分支学科有鱼类形态学、鱼类分类学、鱼类生态学、经济鱼类学、鱼类生理学、鱼类发生学等。</p><h3 id="2-简述关于软骨鱼类和硬骨鱼类的2个学说。"><a href="#2-简述关于软骨鱼类和硬骨鱼类的2个学说。" class="headerlink" title="2.    简述关于软骨鱼类和硬骨鱼类的2个学说。"></a>2.    简述关于软骨鱼类和硬骨鱼类的2个学说。</h3><h3 id="3-现生鱼类可分为哪些类群？"><a href="#3-现生鱼类可分为哪些类群？" class="headerlink" title="3.    现生鱼类可分为哪些类群？"></a>3.    现生鱼类可分为哪些类群？</h3><p>圆口类、软骨鱼纲、硬骨鱼纲。</p><h3 id="4-名词解释："><a href="#4-名词解释：" class="headerlink" title="4.    名词解释："></a>4.    名词解释：</h3><ul><li>鱼：鱼类是终生生活在水中，通常用鳃呼吸，用鳍作为运动器官的变温脊椎动物。</li><li>鱼形动物：同无颌类。</li><li>甲胄鱼类：无颌类在志留纪及泥盆纪中最多，其特征是没有上下颌，鳃呈囊状，无真正的偶鳍。化石无颌类的身体几乎全为厚的骨板和硬的物质所包，故称为甲胄鱼类。</li><li>盾皮鱼类    </li><li>无颌类：最原始的鱼类，骨骼全为软骨，无上下颌，故又称为无颌类。</li><li>软骨鱼类：内骨骼全为软骨。</li><li>硬骨鱼类：内骨骼或多或少为硬骨。<h3 id="5-什么是“宙、代、纪、世-”？它们有一定的时间限度吗？"><a href="#5-什么是“宙、代、纪、世-”？它们有一定的时间限度吗？" class="headerlink" title="5.    什么是“宙、代、纪、世 ”？它们有一定的时间限度吗？"></a>5.    什么是“宙、代、纪、世 ”？它们有一定的时间限度吗？</h3><h3 id="6-为什么我们几乎找不到一条连续的化石线索来证实我们的各种生物演化理论？"><a href="#6-为什么我们几乎找不到一条连续的化石线索来证实我们的各种生物演化理论？" class="headerlink" title="6.    为什么我们几乎找不到一条连续的化石线索来证实我们的各种生物演化理论？"></a>6.    为什么我们几乎找不到一条连续的化石线索来证实我们的各种生物演化理论？</h3><h2 id="二、-鱼体的外部形态"><a href="#二、-鱼体的外部形态" class="headerlink" title="二、    鱼体的外部形态"></a>二、    鱼体的外部形态</h2><h3 id="1-鱼类的头部可以分为哪几部分？"><a href="#1-鱼类的头部可以分为哪几部分？" class="headerlink" title="1.    鱼类的头部可以分为哪几部分？"></a>1.    鱼类的头部可以分为哪几部分？</h3>颐部、颌部、峡部、喉部、胸部。<h3 id="2-鱼类的头部有哪些主要外部器官？各器官构造与鱼类生活习性有何适应性关系？"><a href="#2-鱼类的头部有哪些主要外部器官？各器官构造与鱼类生活习性有何适应性关系？" class="headerlink" title="2.    鱼类的头部有哪些主要外部器官？各器官构造与鱼类生活习性有何适应性关系？"></a>2.    鱼类的头部有哪些主要外部器官？各器官构造与鱼类生活习性有何适应性关系？</h3></li><li>①    口：分为端位口、上位口、下位口，主要与捕食习性有关。</li><li>②    须：是鱼类的触觉器官，同时分布有味蕾，具有辅助觅食功能。</li><li>③    眼：位置与习性有关。</li><li>④    鼻：</li><li>⑤    鳃裂和鳃孔</li><li>⑥    喷水孔<h3 id="3-鱼类常见的体型有哪些？"><a href="#3-鱼类常见的体型有哪些？" class="headerlink" title="3.    鱼类常见的体型有哪些？"></a>3.    鱼类常见的体型有哪些？</h3>四种基本类型：纺锤型、侧扁型、平扁型、棒型<h3 id="4-鱼体身上有哪几种鳍？鳍的结构如何？鳍条可分为几种？各有何特征？各鳍有何功能？有哪些变异类型？"><a href="#4-鱼体身上有哪几种鳍？鳍的结构如何？鳍条可分为几种？各有何特征？各鳍有何功能？有哪些变异类型？" class="headerlink" title="4.    鱼体身上有哪几种鳍？鳍的结构如何？鳍条可分为几种？各有何特征？各鳍有何功能？有哪些变异类型？"></a>4.    鱼体身上有哪几种鳍？鳍的结构如何？鳍条可分为几种？各有何特征？各鳍有何功能？有哪些变异类型？</h3></li></ul><ol><li>5种，背鳍、臀鳍、尾鳍、胸鳍、腹鳍。</li><li>鳍由属于内骨胳的支鳍骨（担鳍骨）和鳍条组成，外附肌肉。</li><li>鳍条可以分为两种类型：角质鳍条（不分支不分节，为软骨鱼类所特有）、<br>鳞质鳍条（由鳞片衍生而来，又称骨质鳍条，为硬骨鱼类所特有。种类有：分枝鳍条、不分枝鳍条、假棘、鳍棘（真棘））。</li><li>功能：维持直立和平衡的有背鳍、臀鳍、胸鳍和腹鳍，推进鱼体运动和转向的有尾鳍和胸鳍。<h3 id="5-如何解析鳍式？"><a href="#5-如何解析鳍式？" class="headerlink" title="5.    如何解析鳍式？"></a>5.    如何解析鳍式？</h3><h2 id="三、-皮肤及其衍生物"><a href="#三、-皮肤及其衍生物" class="headerlink" title="三、    皮肤及其衍生物"></a>三、    皮肤及其衍生物</h2></li><li>鱼的皮肤组成是怎样的？<br>分为表皮和真皮。</li></ol><p><img src="http://i.imgur.com/KV7dmna.png" alt=""></p><h3 id="2-鱼类的体色是如何形成的？有何生物学意义？"><a href="#2-鱼类的体色是如何形成的？有何生物学意义？" class="headerlink" title="2.    鱼类的体色是如何形成的？有何生物学意义？"></a>2.    鱼类的体色是如何形成的？有何生物学意义？</h3><ul><li>a.    色素细胞起源于中胚层，主要分布于真皮的疏松层和外膜层，通常在表皮和真皮的致密层无色素细胞。共有四种色素细胞：黑色素细胞、黄色素细胞、红色素细胞和虹彩细胞。鱼类色泽的变化，系由于色素细胞内色素颗粒的扩散与集中所致。可因环境、年龄、性别、健康状况和感情冲动而变化。</li><li>b.    鱼类的体色在一定程度上具有保护自己、攻击对方或迷惑对方、逃避敌害的作用。这对鱼类的生存有着特殊意义。</li><li>性别色：雌雄鱼体色不同的现象。</li><li>警戒色：一些鱼类所具有的具有警戒作用的体色。</li><li>伪装色：与环境协调一致的体色。               </li><li>拟态：有些鱼类不仅体色与环境一致，而且体态也象周围的环境的现象称拟态。<h3 id="3-鱼类的粘液有何生物学意义？"><a href="#3-鱼类的粘液有何生物学意义？" class="headerlink" title="3.    鱼类的粘液有何生物学意义？"></a>3.    鱼类的粘液有何生物学意义？</h3></li><li>a.    可以减少水和鱼体表面的摩擦阻力，增加鱼的游泳速率。</li><li>b.    可以减少细菌或寄生虫类对鱼体的侵袭。</li><li>c.    使鱼体润滑，不易被捕捉，或被捕后易于挣脱滑逃。</li><li>d.    能协助调节皮肤表面的渗透作用。</li><li>e.    有些鱼的粘液还具有类似明矾的净水作用，可使悬浮于水中的泥沙污物迅速沉淀，如豆齿鳗。<h3 id="4-认识鱼类的几种鳞片类型，能说出分别属于什么鱼类。"><a href="#4-认识鱼类的几种鳞片类型，能说出分别属于什么鱼类。" class="headerlink" title="4.    认识鱼类的几种鳞片类型，能说出分别属于什么鱼类。"></a>4.    认识鱼类的几种鳞片类型，能说出分别属于什么鱼类。</h3></li><li>盾鳞：软骨鱼类特有；外形上分为鳞棘和基板，又称皮齿。</li><li>硬鳞：埋在真皮中的菱形骨板，成行排列；硬骨鱼纲中硬鳞鱼类特有。</li><li>骨鳞：真骨鱼类所有，覆瓦状排列；分为圆鳞、栉鳞。</li><li>骨鳞构造：鳞嵴：鳞片表面形成的一圈一圈的隆起，又称环片，它在大多数鱼类中作同心圆排列。</li><li>鳞焦：鳞嵴的中心区域。</li><li>鳞沟：鳞片上从鳞焦向四方辐射排列的凹沟。<h3 id="5-怎样解析鱼的鳞式？"><a href="#5-怎样解析鱼的鳞式？" class="headerlink" title="5.    怎样解析鱼的鳞式？"></a>5.    怎样解析鱼的鳞式？</h3></li></ul><p><img src="http://i.imgur.com/NeSu70J.png" alt=""></p><h2 id="四、-骨骼和肌肉系统"><a href="#四、-骨骼和肌肉系统" class="headerlink" title="四、    骨骼和肌肉系统"></a>四、    骨骼和肌肉系统</h2><h3 id="1-鱼类骨骼的分类"><a href="#1-鱼类骨骼的分类" class="headerlink" title="1.    鱼类骨骼的分类"></a>1.    鱼类骨骼的分类</h3><p><img src="http://i.imgur.com/sa4CeCw.png" alt=""></p><h3 id="2-软骨鱼类和硬骨鱼类的骨骼系统各有何特点？"><a href="#2-软骨鱼类和硬骨鱼类的骨骼系统各有何特点？" class="headerlink" title="2.    软骨鱼类和硬骨鱼类的骨骼系统各有何特点？"></a>2.    软骨鱼类和硬骨鱼类的骨骼系统各有何特点？</h3><ul><li>脑颅</li><li>软骨鱼类的脑颅为一个完整的软骨，没有骨片分化，相当于高等脊椎动物的原始颅骨状态，故又称原颅。</li><li>硬骨鱼类的脑颅骨化为许多小骨片，有软骨化骨，也有膜骨。<h3 id="3-软骨化骨、膜骨、韦伯氏器、肩带、腰带等概念。"><a href="#3-软骨化骨、膜骨、韦伯氏器、肩带、腰带等概念。" class="headerlink" title="3.    软骨化骨、膜骨、韦伯氏器、肩带、腰带等概念。"></a>3.    软骨化骨、膜骨、韦伯氏器、肩带、腰带等概念。</h3></li><li>软骨化骨：指完整地经过膜质期、软骨期及硬骨期三个阶段形成的硬骨。</li><li>膜骨：由膜质期直接经硬骨细胞骨化而形成的硬骨，它不经过软骨期。</li><li>韦伯氏器：指位于椎骨两侧，由第1~3椎骨的一部分所特化而成的带状骨、舶状骨、间插骨和三角骨所组成的连接鳔和内耳的一组小骨片。</li><li>肩带与腰带：支持胸鳍的骨骼为肩带，支持腹鳍的骨骼为腰带。</li></ul><h3 id="4-尾鳍的四种类型。"><a href="#4-尾鳍的四种类型。" class="headerlink" title="4.    尾鳍的四种类型。"></a>4.    尾鳍的四种类型。</h3><p><img src="http://i.imgur.com/NL8CkD7.png" alt=""></p><h4 id="为什么说鳍是协助运动的器官？"><a href="#为什么说鳍是协助运动的器官？" class="headerlink" title="为什么说鳍是协助运动的器官？"></a>为什么说鳍是协助运动的器官？</h4><p>肌肉才是鱼的主要运动器官。</p><h4 id="鱼类肌肉有哪些类别？"><a href="#鱼类肌肉有哪些类别？" class="headerlink" title="鱼类肌肉有哪些类别？"></a>鱼类肌肉有哪些类别？</h4><p>按组织结构、分布特点或生理作用分为：<br>平滑肌:——非随意肌（内脏肌）；<br>心脏肌——非随意肌（内脏肌）；<br>横纹肌：骨骼肌——随意肌。</p><h4 id="鱼类的发电器官和发光器官来源于什么组织？"><a href="#鱼类的发电器官和发光器官来源于什么组织？" class="headerlink" title="鱼类的发电器官和发光器官来源于什么组织？"></a>鱼类的发电器官和发光器官来源于什么组织？</h4><p>发电器官来自于肌肉的变异；发光器官由皮肤衍生而来。</p><h4 id="鱼类发光有何生物学意义？"><a href="#鱼类发光有何生物学意义？" class="headerlink" title="鱼类发光有何生物学意义？"></a>鱼类发光有何生物学意义？</h4><p>辨识同类、求偶繁殖、引诱食物、惊吓拒敌。</p><h2 id="五、-消化系统"><a href="#五、-消化系统" class="headerlink" title="五、    消化系统"></a>五、    消化系统</h2><h3 id="1-鱼类的消化系统的组成如何？试分析鱼类口、齿、鳃耙、胃、肠等的结构和机能与其食性的关系。"><a href="#1-鱼类的消化系统的组成如何？试分析鱼类口、齿、鳃耙、胃、肠等的结构和机能与其食性的关系。" class="headerlink" title="1.    鱼类的消化系统的组成如何？试分析鱼类口、齿、鳃耙、胃、肠等的结构和机能与其食性的关系。"></a>1.    鱼类的消化系统的组成如何？试分析鱼类口、齿、鳃耙、胃、肠等的结构和机能与其食性的关系。</h3><p>鱼类消化系统的组成：消化管、各种消化腺。</p><p>消化管为一肌肉的管子，起自口，最后从泄殖腔或肛门开口于外，包括口咽腔、食道、胃、肠等部分。</p><p>鱼类主要的消化腺为肝脏、胰脏及胃腺。</p><ul><li>a.    齿与鱼类食性的适应性关系：</li><li>a)    凶猛捕食性鱼类(海鳗、带鱼)： 齿锋利， 犬牙状。</li><li>b)    凶猛的鲨鱼：犬牙状，牙齿边缘锯齿状。</li><li>c)    温和滤食性鱼类：牙一般细小，退化。</li><li>d)    食贝鱼类：具臼状齿或铺石状齿。</li><li>e)    食水草鱼类：具梳状齿。</li><li>b.    鱼类鳃耙数目、形状与鱼的食性的关系：</li></ul><p>食浮游生物鱼类：鳃耙细、密、长；<br>若食物较大，且有相当的运动能力，则鳃耙粗长而数少，有粗糙的突起或绒齿，可帮助抓牢和吞咽食物。</p><p>硬骨鱼类肠的长度及盘曲程度因种类及食性而异：<br>肉食性的鱼类：肠管较短，仅为体长的1／3—1／4，多呈直管状或有一个弯曲；<br>草食性鱼类：肠较长，一般为体长的2—5倍，有的甚至达15倍，在腹腔中盘曲较多；<br>杂食性鱼类：肠短于草食者而长于肉食者。</p><h3 id="2-肝脏有哪些机能？"><a href="#2-肝脏有哪些机能？" class="headerlink" title="2.    肝脏有哪些机能？"></a>2.    肝脏有哪些机能？</h3><p>制造胆汁：胆汁不含消化酶，但能促进脂肪的分解。胆囊有输胆管通到肠的前端。<br>抗毒：肝能从血液中扣留无关的物质，并通过胆管把它们排除出去。<br>储存糖元以调节血糖的平衡。</p><h2 id="六、-循环系统"><a href="#六、-循环系统" class="headerlink" title="六、    循环系统"></a>六、    循环系统</h2><h3 id="1-鱼类血液的成分有哪些，与哺乳动物血液成分有哪些不同"><a href="#1-鱼类血液的成分有哪些，与哺乳动物血液成分有哪些不同" class="headerlink" title="1.    鱼类血液的成分有哪些，与哺乳动物血液成分有哪些不同?"></a>1.    鱼类血液的成分有哪些，与哺乳动物血液成分有哪些不同?</h3><ul><li>a.    由血浆(blood plasma)及血球(blood cell)组成。血球由红血球、白血球和血栓细胞（或称血小板）等组成。</li><li>b.    不同点：红血球：鱼的红血球呈扁圆形。一般具有细胞核。哺乳动物成熟的红细胞无细胞核。血栓细胞：无色，小于红血球。血栓细胞与血液的凝固作用有关。鱼类的血栓细胞与哺乳类的血小板的不同点是它是一个真细胞，有核和细胞质。<h3 id="2-软骨鱼、低等硬骨鱼心脏与真骨鱼心脏的区别。"><a href="#2-软骨鱼、低等硬骨鱼心脏与真骨鱼心脏的区别。" class="headerlink" title="2.    软骨鱼、低等硬骨鱼心脏与真骨鱼心脏的区别。"></a>2.    软骨鱼、低等硬骨鱼心脏与真骨鱼心脏的区别。</h3>结构：有围心膜包在外面，典型的心脏由三部分组成：静脉窦、心耳、 心室。<br>动脉圆锥：位于软骨鱼类及低等硬骨鱼类心室前方，能自主搏动，为心脏的一部分。<br>动脉球：真骨鱼类动脉圆锥退化，腹主动脉基部扩大成动脉球，不属于心脏。<h3 id="3-试述鱼类动脉循环的主要途径。"><a href="#3-试述鱼类动脉循环的主要途径。" class="headerlink" title="3.    试述鱼类动脉循环的主要途径。"></a>3.    试述鱼类动脉循环的主要途径。</h3>鳃：腹侧主动脉 → 入鳃动脉 → 毛细血管→ 鳃丝、鳃小片→出鳃动脉 → 鳃上动脉 → 背主动脉。</li></ul><p>头部：背主动脉或第一出鳃动脉 → 颈总动脉：分布到脑部、上下颌、眼、鼻及吻部等各区域。</p><p>头环：在硬骨鱼类中，左右背主动脉和颈动脉连合而成的环状结构。 </p><h3 id="4-鱼的造血器官有哪些？"><a href="#4-鱼的造血器官有哪些？" class="headerlink" title="4.    鱼的造血器官有哪些？"></a>4.    鱼的造血器官有哪些？</h3><p>脾脏、淋巴髓质组织、赖迪氏器官、头肾</p><h3 id="5-解释“淋巴心”。"><a href="#5-解释“淋巴心”。" class="headerlink" title="5.    解释“淋巴心”。"></a>5.    解释“淋巴心”。</h3><p>淋巴心：位于最后一脊椎骨的下面，呈圆形，是由尾静脉 的一部分发育而成，它能不断地搏动，淋巴心有瓣膜调节本身的搏动和淋巴的流向。</p><h2 id="七、-神经系统"><a href="#七、-神经系统" class="headerlink" title="七、    神经系统"></a>七、    神经系统</h2><h3 id="1-试述鱼脑的基本结构及各部分的主要机能、鱼脑构造的生态适应性。"><a href="#1-试述鱼脑的基本结构及各部分的主要机能、鱼脑构造的生态适应性。" class="headerlink" title="1.    试述鱼脑的基本结构及各部分的主要机能、鱼脑构造的生态适应性。"></a>1.    试述鱼脑的基本结构及各部分的主要机能、鱼脑构造的生态适应性。</h3><p>鱼脑分化为五个区：端脑、间脑、中脑、小脑、延脑。</p><h4 id="a-端脑：嗅脑、大脑"><a href="#a-端脑：嗅脑、大脑" class="headerlink" title="a.    端脑：嗅脑、大脑"></a>a.    端脑：嗅脑、大脑</h4><p>嗅脑：软骨鱼类：嗅球、嗅束两个部分。<br>硬骨鱼类：嗅球及嗅束或仅为嗅叶。<br>大脑：左右两个大脑半球。大脑背壁无神经组织，腹壁上有许多神经细胞集中而形成纹状体，此乃真正脑组织所在。大脑半球内各有一脑腔，称为侧脑室。<br>功能：嗅觉中枢。  </p><h4 id="b-间脑"><a href="#b-间脑" class="headerlink" title="b.    间脑"></a>b.    间脑</h4><p>间脑可分为上丘脑、丘脑及下丘脑三个部分；<br>间脑对于色素细胞的影响很明显，能使鱼体变黑。</p><h4 id="c-中脑"><a href="#c-中脑" class="headerlink" title="c.    中脑"></a>c.    中脑</h4><p>由腹面的基部（或称被盖）及背面的顶盖两部分组成。顶盖分为两个半球，称为视叶。中脑内的空腔称中脑腔。<br>中脑是鱼类最高视觉中枢所在。中脑有通向延脑的神经纤维，它对鱼体的运动和平衡有调节作用。 </p><h4 id="d-小脑"><a href="#d-小脑" class="headerlink" title="d.    小脑"></a>d.    小脑</h4><p>位于中脑后方，在许多硬骨鱼类它向前方突出小脑瓣伸入中脑腔，有些鱼类在小脑的两侧有耳状或球状突起，称为小脑鬈。<br>功能：鱼类运动的主要调节中枢。它维持平衡和姿势，掌握运动的协调，节制肌肉的张力。小脑鬈与内耳及侧线器官有密切联系，所以鱼类的小脑兼为听觉和侧线的会同中枢。 </p><h4 id="e-延脑"><a href="#e-延脑" class="headerlink" title="e.    延脑"></a>e.    延脑</h4><p>脑的最后部分，与脊髓无明晰的分界。<br>功能：包括好几方面的神经中枢：听觉、侧线感觉中枢、呼吸中枢、味觉中枢、皮肤感觉中枢、色素细胞调节中枢。</p><h4 id="f-鱼脑构造的生态适应"><a href="#f-鱼脑构造的生态适应" class="headerlink" title="f.    鱼脑构造的生态适应"></a>f.    鱼脑构造的生态适应</h4><ul><li>主要借视觉器官觅取饵料的外海性上层鱼类：视叶特别发达，小脑比较大，如鲐、飞鱼等。</li><li>以摄取小型浮游生物为主的外海上层鱼类：触觉中枢往往比较发达，有发达而分化的延脑。</li><li>底栖生活的鱼类：往往具有发达的纹状体，小脑通常较小。延脑特别分化。</li><li>浅海活泼游泳的鱼类：脑的特点界于外海性上层鱼类和底层鱼类之间，小脑比上层鱼类小而比底层鱼类发达，视叶比底层鱼类发达，嗅叶比上层鱼类发达，如鲈、鳚等。</li></ul><h3 id="2-鱼类的脑神经有哪些？各属何种类型？"><a href="#2-鱼类的脑神经有哪些？各属何种类型？" class="headerlink" title="2.    鱼类的脑神经有哪些？各属何种类型？"></a>2.    鱼类的脑神经有哪些？各属何种类型？</h3><ul><li>感觉神经：嗅神经、视神经、听神经（Ⅷ）；</li><li>运动神经：动眼神经、滑车神经、外展神经；</li><li>混合神经：三叉神经、面神经、舌咽神经、迷走神经。</li></ul><h2 id="八、-感觉器官"><a href="#八、-感觉器官" class="headerlink" title="八、    感觉器官"></a>八、    感觉器官</h2><h3 id="1-鱼类侧线的结构和功能及其机理如何？"><a href="#1-鱼类侧线的结构和功能及其机理如何？" class="headerlink" title="1.    鱼类侧线的结构和功能及其机理如何？"></a>1.    鱼类侧线的结构和功能及其机理如何？</h3><p>侧线是沟状或管状的皮肤感觉器，分布在头部及身体两侧。<br>侧线管在体侧通过鳞片；在头部常埋于膜骨内。<br>侧线管内充满粘液，它的感觉器神经丘即浸润在粘液中。当水流冲击身体，水的压力通过侧线管上的小孔进入管内，传递于粘液，引起粘液流动，并使感觉顶产生摇动，从而把感觉细胞获得的外来刺激通过感觉神经纤维传递到神经中枢。</p><h3 id="2-了解鱼类的视觉、听觉和嗅觉器官。"><a href="#2-了解鱼类的视觉、听觉和嗅觉器官。" class="headerlink" title="2.    了解鱼类的视觉、听觉和嗅觉器官。"></a>2.    了解鱼类的视觉、听觉和嗅觉器官。</h3><h4 id="a-听觉器官——内耳"><a href="#a-听觉器官——内耳" class="headerlink" title="a.    听觉器官——内耳"></a>a.    听觉器官——内耳</h4><p>鱼类的听觉器官只有内耳，没有中耳及外耳。<br>内耳的两个重要作用：平衡与听觉。<br>鱼辨别方向依靠皮肤感觉器而不是外耳。</p><h4 id="b-视觉器官——眼"><a href="#b-视觉器官——眼" class="headerlink" title="b.    视觉器官——眼"></a>b.    视觉器官——眼</h4><p>鱼类眼球是由巩膜、脉络膜及视网膜三层被膜组成。<br>眼球的最内层为视网膜，是产生视觉作用所在的部位。有神经分布到视网膜上。</p><h4 id="c-嗅觉器官——嗅囊"><a href="#c-嗅觉器官——嗅囊" class="headerlink" title="c.    嗅觉器官——嗅囊"></a>c.    嗅觉器官——嗅囊</h4><p>嗅囊是由一些多褶的嗅觉上皮组成，它分化为嗅觉细胞和支持细胞；通过外鼻孔与外界相通。<br>鱼类的嗅囊能感受由食物所产生的化学刺激，有感觉气味的能力。<br>鱼类嗅粘膜有初级嗅板和次级嗅板之分，次级嗅板附生在初级嗅板上</p><h2 id="九、-内分泌器官"><a href="#九、-内分泌器官" class="headerlink" title="九、    内分泌器官"></a>九、    内分泌器官</h2><h3 id="鱼类有哪些内分泌腺？各与什么功能有关？"><a href="#鱼类有哪些内分泌腺？各与什么功能有关？" class="headerlink" title="鱼类有哪些内分泌腺？各与什么功能有关？"></a>鱼类有哪些内分泌腺？各与什么功能有关？</h3><h5 id="内分泌腺：分泌的物质（激素）不通过导管，而是由血液和体液将其输送到全身各器官、组织和细胞，使之发挥生理效能。"><a href="#内分泌腺：分泌的物质（激素）不通过导管，而是由血液和体液将其输送到全身各器官、组织和细胞，使之发挥生理效能。" class="headerlink" title="内分泌腺：分泌的物质（激素）不通过导管，而是由血液和体液将其输送到全身各器官、组织和细胞，使之发挥生理效能。"></a>内分泌腺：分泌的物质（激素）不通过导管，而是由血液和体液将其输送到全身各器官、组织和细胞，使之发挥生理效能。</h5><p>鱼类的内分泌腺及组织有脑垂体、肾上腺、甲状腺、胸腺、胰岛、后鳃腺、性腺及尾垂体等。</p><ul><li>a.    脑垂体： 分泌的激素可以影响到鱼的生长、体色、控制性腺、甲状腺和肾上腺的发育等等。</li><li>b.    甲状腺：分泌甲状腺素。甲状腺素在生长及器官形成方面有明显的作用。甲状腺素在渗透调节上也可能起若干作用的。比目鱼的变态。</li><li>c.    肾上腺：鱼类没有集中的肾上腺，但是具有与高等脊椎动物肾上腺细胞相应的细胞群——髓质（肾上组织）和皮质（肾间组织）。</li></ul><p>硬骨鱼类的肾上组织分泌的激素为肾上腺素和去甲肾上腺素，能促进心跳，扩大鳃血管，导致黑色素细胞里黑色素粒集中。</p><p>肾间组织分泌的激素为类固醇性质的皮质激素，对渗透压的调节有一定作用，对蛋白质及碳水化合物的代谢有一定影响。<br>斯坦尼斯小体的分泌活动与生殖活动有关。</p><ul><li>d.    胰岛：胰岛或称蓝氏岛。板鳃鱼类的胰岛埋藏在结实的胰脏组织内，硬骨鱼类的胰岛组织存在于胆囊、脾脏、幽门盲囊及小肠的周围，与胰脏是分开的。<br>分泌胰岛素与胰高血糖素。</li><li>e.    其他：<br>胸腺： 在硬骨鱼类一般位于鳃腔背侧，与免疫有关；<br>后鳃腺：是咽部的衍生物。后鳃腺分泌的激素为降钙素，作用是抑制骨盐溶解，使血清钙含量降低，维持血钙的动态平衡。<br>性腺：除了产生卵子和精子以外，同时也是内分泌器官，分泌的激素为性激素。鱼类性激素的产生受脑垂体调节。<br>尾垂体：是尾部脊髓末端背侧膨大的一种内分泌腺体。已知分泌物中有4种活性肽，分别是Urotensin Ⅰ、Ⅱ、Ⅲ、Ⅳ。与渗透压调节、心血管活动和繁殖的调节有关。</li></ul><h2 id="十、-尿殖系统"><a href="#十、-尿殖系统" class="headerlink" title="十、    尿殖系统"></a>十、    尿殖系统</h2><h3 id="1-试述淡水鱼类、海水软骨鱼类和海水硬骨鱼类的渗透压调节机制。"><a href="#1-试述淡水鱼类、海水软骨鱼类和海水硬骨鱼类的渗透压调节机制。" class="headerlink" title="1.    试述淡水鱼类、海水软骨鱼类和海水硬骨鱼类的渗透压调节机制。"></a>1.    试述淡水鱼类、海水软骨鱼类和海水硬骨鱼类的渗透压调节机制。</h3><h4 id="a-淡水鱼类："><a href="#a-淡水鱼类：" class="headerlink" title="a.    淡水鱼类："></a>a.    淡水鱼类：</h4><p>鳃和皮肤吸水；粪便和尿液损失盐分。<br>肾脏排水，鳃上的氯细胞（吸盐细胞）从水中吸收盐分，从食物补充盐分。</p><h4 id="b-海水硬骨鱼类"><a href="#b-海水硬骨鱼类" class="headerlink" title="b.    海水硬骨鱼类"></a>b.    海水硬骨鱼类</h4><p>鳃和皮肤失水；尿液会排除一些水。<br>吞食海水和从食物中获取水分、鳃上的泌盐细胞将多余的盐分排出体外。粪便和尿液也排除多余的盐分。</p><h4 id="c-海水软骨鱼类"><a href="#c-海水软骨鱼类" class="headerlink" title="c.    海水软骨鱼类"></a>c.    海水软骨鱼类</h4><p>通过血液中多量的尿素保持较高的渗透压，从食物获得盐分。鳃和皮肤吸水。肾脏排尿和直肠腺分泌可排除过多的盐分。</p><h3 id="2-软骨鱼类和真骨鱼类的输尿管和生殖导管在发生和构造上有何不同？"><a href="#2-软骨鱼类和真骨鱼类的输尿管和生殖导管在发生和构造上有何不同？" class="headerlink" title="2.    软骨鱼类和真骨鱼类的输尿管和生殖导管在发生和构造上有何不同？"></a>2.    软骨鱼类和真骨鱼类的输尿管和生殖导管在发生和构造上有何不同？</h3><h4 id="a-软骨鱼类"><a href="#a-软骨鱼类" class="headerlink" title="a.    软骨鱼类"></a>a.    软骨鱼类</h4><p>雌体：前肾管纵裂为二；中肾管（吴夫氏管）：与中肾小管相通，担负输尿管的任务；米勒氏管：成为输卵管。<br>雄体：米勒氏管退化消失，中肾管成为输精管，肾脏后部另有一对中肾辅助管集合成输尿管。</p><h4 id="b-硬骨鱼类："><a href="#b-硬骨鱼类：" class="headerlink" title="b.    硬骨鱼类："></a>b.    硬骨鱼类：</h4><p>中肾管为输尿管，米勒氏管退化。</p><h3 id="3-如何鉴别鱼类的性别？"><a href="#3-如何鉴别鱼类的性别？" class="headerlink" title="3.    如何鉴别鱼类的性别？"></a>3.    如何鉴别鱼类的性别？</h3><p>a.    根据第一性征：如直接观察精巢卵巢</p><p>b.    根据第二性征：如色泽的差异、雌雄异形、珠星等。</p><p>婚姻色：许多鱼类在繁殖季节出现鲜艳的色彩，特别在一些雄鱼上更加突出，待生殖季节一过，鲜艳的色彩即行消失，这种色彩称为婚姻色。</p><p>珠星：有一些鱼，到生殖季节，雄鱼身上的个别部位（如鳃盖、鳍条、吻部、头背部等）出现的白色坚硬的锥状突起，又称追星，是表皮细胞特别肥厚和角质化的结果。这在鲤科鱼类中较常见。</p><h3 id="4-鱼类有哪几种生殖方式？"><a href="#4-鱼类有哪几种生殖方式？" class="headerlink" title="4.    鱼类有哪几种生殖方式？"></a>4.    鱼类有哪几种生殖方式？</h3><ol><li>卵生：体外受精、体外发育。</li><li>卵胎生：体内受精，体内发育，胚体的营养靠自身的卵黄或主要依靠卵黄。如软骨鱼类许多种类、硬骨鱼类鳉形目的一些鱼和海鲫、黑鲪、褐菖鲉等。</li><li>胎生（假胎生）：体内受精，体内发育，胚体与母体发生血液循环上的联系。其营养不仅靠卵黄，而且也依靠母体。这类鱼形成类似胎盘的构造，母体的营养通过这种胎盘输送给胚体。这种胎盘在构造上与哺乳动物的胎盘不同，特称之为卵黄胎盘。</li></ol><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="http://share.weiyun.com/4edec98a4c3f461d7382acdf1e7f60d8" target="_blank" rel="noopener">http://share.weiyun.com/4edec98a4c3f461d7382acdf1e7f60d8</a><br><a href="http://share.weiyun.com/2ef6cbc04162f354339013ed89388608" target="_blank" rel="noopener">http://share.weiyun.com/2ef6cbc04162f354339013ed89388608</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;鱼类学&quot;&gt;&lt;a href=&quot;#鱼类学&quot; class=&quot;headerlink&quot; title=&quot;鱼类学&quot;&gt;&lt;/a&gt;鱼类学&lt;/h1&gt;&lt;h2 id=&quot;一、绪论&quot;&gt;&lt;a href=&quot;#一、绪论&quot; class=&quot;headerlink&quot; title=&quot;一、绪论&quot;&gt;&lt;/a&gt;一、绪
      
    
    </summary>
    
    
      <category term="海洋科学" scheme="http://chegde.github.io/tags/%E6%B5%B7%E6%B4%8B%E7%A7%91%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>node-recoding</title>
    <link href="http://chegde.github.io/2016/06/21/node-recoding/"/>
    <id>http://chegde.github.io/2016/06/21/node-recoding/</id>
    <published>2016-06-21T15:34:12.000Z</published>
    <updated>2018-01-05T14:27:02.000Z</updated>
    
    <content type="html"><![CDATA[<p>node 异步特点</p><h2 id="异步编程"><a href="#异步编程" class="headerlink" title="异步编程"></a>异步编程</h2><h4 id="函数式编程"><a href="#函数式编程" class="headerlink" title="函数式编程"></a>函数式编程</h4><h5 id="高阶编程"><a href="#高阶编程" class="headerlink" title="高阶编程"></a>高阶编程</h5><p>高阶函数可以将函数作为输入或返回值.<br>结合node中基本事件模块可以看出,事件的处理方式由高阶函数特性来完成的.<br>如在ECMAscript5中的数组方法 forEach map reduceRight filter every some<br>在自定义事件中,为相同事件注册不同回调,可以灵活处理业务逻辑.</p><h5 id="偏函数用法"><a href="#偏函数用法" class="headerlink" title="偏函数用法"></a>偏函数用法</h5><p>创建一个调用另一个部分 参数或变量已经预置的函数 的函数的用法<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">var isType = function(type) &#123;</span><br><span class="line">    return function(obj) &#123;</span><br><span class="line">        return toString.call(obj) == &apos;[object &apos; + type + &apos;]&apos;;</span><br><span class="line">    &#125;;</span><br><span class="line">&#125;;</span><br><span class="line">var isString = isType(&apos;String&apos;);</span><br><span class="line">var isFunction = isType(&apos;Function&apos;);</span><br></pre></td></tr></table></figure></p><p>通过指定部分参数来产生一个新的定制参数的形式是偏函数</p><h4 id="异步-Promise"><a href="#异步-Promise" class="headerlink" title="异步 Promise"></a><a href="http://www.jdon.com/idea/nodejs/promise.html" target="_blank" rel="noopener">异步 Promise</a></h4><p><a href="http://www.jdon.com/idea/nodejs/promise.html" target="_blank" rel="noopener">用法</a></p><h4 id="异步-EventEmitter"><a href="#异步-EventEmitter" class="headerlink" title="异步 EventEmitter"></a><a href="http://cnodejs.org/topic/533d6edbc2621e680800e0ea" target="_blank" rel="noopener">异步 EventEmitter</a></h4><h3 id="控制流"><a href="#控制流" class="headerlink" title="控制流"></a>控制流</h3><p>如何进行同步</p><ol><li>使用回调 callback</li><li>组成函数数组 递归调用</li><li>调用类库<ol><li><a href="https://github.com/caolan/async" target="_blank" rel="noopener">async</a></li><li><a href="https://github.com/creationix/step" target="_blank" rel="noopener">step</a></li></ol></li></ol><h4 id="协程-generators"><a href="#协程-generators" class="headerlink" title="协程 generators"></a><a href="http://www.jdon.com/idea/nodejs/generators.html" target="_blank" rel="noopener">协程 generators</a></h4><ol><li><a href="http://www.jdon.com/idea/nodejs/generators-vs-fibers.html" target="_blank" rel="noopener">示例 generators vs fibers</a></li><li><a href="http://www.jdon.com/idea/nodejs/generators.html" target="_blank" rel="noopener">示例 generators</a></li></ol><p>参考链接:</p><p><a href="https://howtonode.org/control-flow-part-ii" target="_blank" rel="noopener">control flow in node</a></p><p><a href="http://blog.csdn.net/yanghua_kobe/article/details/8521962" target="_blank" rel="noopener">callback or promises?</a></p><p><a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Access_control_CORS" target="_blank" rel="noopener">cofs-http</a></p><p><a href="http://code.tutsplus.com/tutorials/restful-api-design-with-nodejs-restify--cms-22637" target="_blank" rel="noopener">RESTful API Design With NodeJS &amp; Restify</a></p><p><a href="https://github.com/frodefi/node-mysql-json-server" target="_blank" rel="noopener">node-mysql-json-server</a></p><p><a href="https://www.owasp.org/index.php/OWASP_AJAX_Security_Guidelines#Always_return_JSON_with_an_Object_on_the_outside" target="_blank" rel="noopener">ajax security cheat sheet</a></p><h4 id="angular2问题解集"><a href="#angular2问题解集" class="headerlink" title="angular2问题解集"></a>angular2问题解集</h4><p><a href="http://stackoverflow.com/questions/35534959/access-key-and-value-of-object-using-ngfor/35536052#35536052" target="_blank" rel="noopener">关于json解析成对象数组时</a></p><p><a href="http://stackoverflow.com/questions/35647365/how-to-display-json-object-using-ngfor/35647396#35647396" target="_blank" rel="noopener">how to display json object using ngfor</a></p><p><a href="https://angular.cn/docs/ts/latest/guide/server-communication.html#!#extract-data" target="_blank" rel="noopener">server-communication</a></p><p><a href="https://fetch.spec.whatwg.org/#response-class" target="_blank" rel="noopener">fetch standard</a></p><p><a href="http://reactlet.com/" target="_blank" rel="noopener">others works</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;node 异步特点&lt;/p&gt;
&lt;h2 id=&quot;异步编程&quot;&gt;&lt;a href=&quot;#异步编程&quot; class=&quot;headerlink&quot; title=&quot;异步编程&quot;&gt;&lt;/a&gt;异步编程&lt;/h2&gt;&lt;h4 id=&quot;函数式编程&quot;&gt;&lt;a href=&quot;#函数式编程&quot; class=&quot;headerlin
      
    
    </summary>
    
    
      <category term="javascript" scheme="http://chegde.github.io/tags/javascript/"/>
    
  </entry>
  
</feed>
